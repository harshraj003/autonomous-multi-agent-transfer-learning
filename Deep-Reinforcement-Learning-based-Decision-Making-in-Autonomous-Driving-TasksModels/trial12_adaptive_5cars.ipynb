{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d49557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### How to Use Daily (No Training!)\n",
       "- Set a checkpoint episode (e.g., 200) in any “LOAD & EVALUATE” cell.\n",
       "- Run only the “LOAD & EVALUATE” cells you need:\n",
       "  - Merge-v0 (state)\n",
       "  - highway-fast-v0 (state)\n",
       "  - Transfer: merge -> highway-fast-v0 (state)\n",
       "  - Merge-v0 (CNN/observation)\n",
       "  - Multi-Agent (shared policy)\n",
       "- Videos will be saved in `Videos/` and auto-played in the notebook.\n",
       "- You never need to retrain. If a checkpoint doesn’t exist, the loader will fall back to the latest available.\n",
       "- All paths use `path_HW5` which defaults to your workspace; change it if needed.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 1 – HOW TO USE DAILY (Markdown rendered via code)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import HTML, display, Video\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### How to Use Daily (No Training!)\n",
    "- Set a checkpoint episode (e.g., 200) in any “LOAD & EVALUATE” cell.\n",
    "- Run only the “LOAD & EVALUATE” cells you need:\n",
    "  - Merge-v0 (state)\n",
    "  - highway-fast-v0 (state)\n",
    "  - Transfer: merge -> highway-fast-v0 (state)\n",
    "  - Merge-v0 (CNN/observation)\n",
    "  - Multi-Agent (shared policy)\n",
    "- Videos will be saved in `Videos/` and auto-played in the notebook.\n",
    "- You never need to retrain. If a checkpoint doesn’t exist, the loader will fall back to the latest available.\n",
    "- All paths use `path_HW5` which defaults to your workspace; change it if needed.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c592adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu | Base path: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 – IMPORTS & GLOBAL SETTINGS\n",
    "\n",
    "import os\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from itertools import count\n",
    "from collections import deque, namedtuple\n",
    "from statistics import mean, median\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.stats import norm, t\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "\n",
    "import gymnasium as gym\n",
    "import highway_env\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from IPython.display import HTML, display\n",
    "import imageio\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Base project path: default to this workspace; override via env var if needed\n",
    "DEFAULT_BASE = str(Path.cwd().resolve())\n",
    "path_HW5 = os.getenv(\"DRL_PROJECT_PATH\", DEFAULT_BASE)\n",
    "if not path_HW5.endswith(os.sep):\n",
    "    path_HW5 += os.sep\n",
    "\n",
    "# Ensure required directories\n",
    "for subdir in ['Models', 'Data_Average_Reward', 'Videos', 'Images']:\n",
    "    os.makedirs(os.path.join(path_HW5, subdir), exist_ok=True)\n",
    "\n",
    "# Device selection\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} | Base path: {path_HW5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23476837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3 – HYPERPARAMETERS\n",
    "\n",
    "BUFFER_SIZE = int(1e5)\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "TAU = 1e-3\n",
    "LR = 5e-4\n",
    "UPDATE_EVERY = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e38c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4 – NEURAL NETWORKS (Linear + CNN)\n",
    "\n",
    "class QNetwork_Linear(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_size, 125), nn.ReLU(),\n",
    "            nn.Linear(125, 125), nn.ReLU(),\n",
    "            nn.Linear(125, action_size)\n",
    "        )\n",
    "    def forward(self, state):\n",
    "        return self.net(state)\n",
    "\n",
    "class QNetwork_CNN(nn.Module):\n",
    "    def __init__(self, action_size, seed):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5, stride=2, padding=2), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((8, 8)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # Avoid LazyLinear: fixed in_features for stability with checkpoints\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128 * 8 * 8, 256), nn.ReLU(),\n",
    "            nn.Linear(256, action_size)\n",
    "        )\n",
    "    def forward(self, state):\n",
    "        return self.head(self.features(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97e3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5 – REPLAY BUFFER\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\",\"action\",\"reward\",\"next_state\",\"done\"])\n",
    "        random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.memory.append(self.experience(state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(device)\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6f91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6 – AGENT (epsilon-greedy; soft-update fixed)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, network_type, seed):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        random.seed(seed)\n",
    "        self.network_type = network_type.lower()\n",
    "\n",
    "        # Initialize local/target networks\n",
    "        if self.network_type == 'linear':\n",
    "            self.qnetwork_local = QNetwork_Linear(state_size, action_size, seed).to(device)\n",
    "            self.qnetwork_target = QNetwork_Linear(state_size, action_size, seed).to(device)\n",
    "        else:\n",
    "            self.qnetwork_local = QNetwork_CNN(action_size, seed).to(device)\n",
    "            self.qnetwork_target = QNetwork_CNN(action_size, seed).to(device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        self.t_step = 0\n",
    "\n",
    "        # Stable resize for observation (screen) inputs\n",
    "        self.resize = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((80, 80), interpolation=Image.Resampling.BICUBIC),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def get_screen(self, screen):\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255.0\n",
    "        screen = torch.from_numpy(screen).permute(2, 0, 1)  # HWC -> CHW\n",
    "        return self.resize(screen).unsqueeze(0)  # [1, 3, H, W]\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        # Learn every UPDATE_EVERY steps if enough samples\n",
    "        if self.t_step == 0 and len(self.memory) > BATCH_SIZE:\n",
    "            self.learn(self.memory.sample())\n",
    "\n",
    "    def act(self, state, eps=0.0):\n",
    "        # Epsilon-greedy action\n",
    "        if self.network_type == 'linear':\n",
    "            state_t = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        else:\n",
    "            state_t = state.to(device)  # already [1, 3, H, W]\n",
    "\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state_t)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        if random.random() > eps:\n",
    "            # Greedy action from Q-values\n",
    "            return int(np.argmax(action_values.cpu().data.numpy()))\n",
    "        # Random exploration\n",
    "        return int(random.choice(np.arange(self.action_size)))\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        with torch.no_grad():\n",
    "            q_targets_next = self.qnetwork_target(next_states).max(1, keepdim=True)[0]\n",
    "            q_targets = rewards + GAMMA * q_targets_next * (1 - dones)\n",
    "        q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "        loss = F.mse_loss(q_expected, q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.qnetwork_local.parameters(), 1.0)\n",
    "        self.optimizer.step()\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_update(local_model, target_model, tau):\n",
    "        # Polyak update: θ_target ← τ θ_local + (1-τ) θ_target\n",
    "        with torch.no_grad():\n",
    "            for tp, lp in zip(target_model.parameters(), local_model.parameters()):\n",
    "                tp.data.copy_(tau * lp.data + (1.0 - tau) * tp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddd292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8 – VISUALIZATION HELPERS\n",
    "\n",
    "class show_and_plot:\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def show_video(self, directory, file_or_prefix):\n",
    "        directory = directory if directory.endswith(os.sep) else directory + os.sep\n",
    "        exact = os.path.join(directory, file_or_prefix)\n",
    "        if os.path.exists(exact):\n",
    "            mp4 = exact\n",
    "        else:\n",
    "            candidates = sorted(glob.glob(os.path.join(directory, f\"{file_or_prefix}*.mp4\")))\n",
    "            if not candidates:\n",
    "                any_mp4 = sorted(glob.glob(os.path.join(directory, \"*.mp4\")))\n",
    "                print(\"Available videos:\", [os.path.basename(x) for x in any_mp4])\n",
    "                print(f\"Not found: {exact}\")\n",
    "                return\n",
    "            mp4 = candidates[-1]\n",
    "        print(f\"Displaying: {mp4}\")\n",
    "        with open(mp4, 'rb') as f:\n",
    "            encoded = base64.b64encode(f.read()).decode('ascii')\n",
    "        display(HTML(f'''\n",
    "        <video alt=\"eval\" autoplay loop controls style=\"height: 220px; width: 860px;\">\n",
    "            <source src=\"data:video/mp4;base64,{encoded}\" type=\"video/mp4\" />\n",
    "        </video>\n",
    "        '''))\n",
    "\n",
    "    def plot_training_result(self, episodes_rewards, ax, title, label, window=20, stride=5, alpha=0.3):\n",
    "        n_iter, n_episode = episodes_rewards.shape\n",
    "        smooth_reward = [np.mean(episodes_rewards[:, i*stride:i*stride+window], axis=1)\n",
    "                         for i in range(int((n_episode - window)/stride) + 1)]\n",
    "        smooth_reward = np.array(smooth_reward).T\n",
    "        X = range(1, len(smooth_reward[0])*stride + 1, stride)\n",
    "        x_bar = np.mean(smooth_reward, axis=0)\n",
    "        sigma = np.std(smooth_reward, axis=0)\n",
    "        SE = sigma / np.sqrt(max(1, n_iter))\n",
    "        interval = 1 - alpha\n",
    "        stat = t.interval(interval, df=max(1, n_iter-1))[1] if n_iter < 30 else norm.interval(interval)[1]\n",
    "        ME = stat * SE\n",
    "        ax.plot(X, x_bar, label=label)\n",
    "        if n_iter >= 2:\n",
    "            ax.fill_between(X, x_bar - ME, x_bar + ME, alpha=alpha)\n",
    "        ax.set_xlabel(\"Episodes\")\n",
    "        ax.set_ylabel(\"Average Reward\")\n",
    "        ax.set_title(f\"{title}\\nwindow={window}, stride={stride}\")\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2802b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9 – UTILS: CHECKPOINT DISCOVERY\n",
    "\n",
    "def find_latest_checkpoint(model_dir: str, pattern: str) -> tuple[str, int] | tuple[None, None]:\n",
    "    files = glob.glob(os.path.join(model_dir, pattern))\n",
    "    if not files:\n",
    "        return None, None\n",
    "    def _ep(p):\n",
    "        m = re.search(r'_(\\d+)\\.pth$', os.path.basename(p))\n",
    "        return int(m.group(1)) if m else -1\n",
    "    best = max(files, key=_ep)\n",
    "    return best, _ep(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a46e6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing highway-v0 environment...\n",
      "Frame shape: (150, 600, 3)\n",
      "Frame shape: (150, 600, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 10 – TEST ENVIRONMENT RENDERING (Quick Sanity)\n",
    "\n",
    "print(\"Visualizing highway-v0 environment...\")\n",
    "env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "cfg = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"vehicles_count\": 5,\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "        \"absolute\": False\n",
    "    },\n",
    "    \"policy_frequency\": 10\n",
    "}\n",
    "if hasattr(env, \"configure\"): env.configure(cfg)\n",
    "else: env.unwrapped.config.update(cfg)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "frame = env.render()\n",
    "print(\"Frame shape:\", None if frame is None else frame.shape)\n",
    "if frame is not None and np.mean(frame) > 0:\n",
    "    img_path = os.path.join(path_HW5, 'Videos', 'debug_frame_highway-v0.png')\n",
    "    imageio.imwrite(img_path, frame)\n",
    "    plt.imshow(frame); plt.title(\"highway-v0 sample frame\"); plt.axis('off'); plt.show()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3ac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfcf0db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using checkpoint: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\1_Models_merge\\Models_Run_1\\checkpoint_dqn_state_merge-v0_target_200.pth\n",
      "Instantiated Agent for evaluation (state-based).\n",
      "Loaded checkpoint into agent.qnetwork_local (and target if compatible).\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "[Merge Eval] episode 1 reward: 4.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "[Merge Eval] episode 2 reward: 7.18\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashFalse\n",
      "overFalse\n",
      "crashTrue\n",
      "overFalse\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "[Merge Eval] episode 3 reward: 5.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 11 – Load & Evaluate Merge-v0 (State)\n",
    "def _unpack_reset(res):\n",
    "    if isinstance(res, tuple) and len(res) >= 1:\n",
    "        return res[0]\n",
    "    return res\n",
    "\n",
    "def _unpack_step(res):\n",
    "    if len(res) == 4:\n",
    "        obs, reward, done, info = res\n",
    "        return obs, reward, done, info\n",
    "    elif len(res) == 5:\n",
    "        obs, reward, terminated, truncated, info = res\n",
    "        done = bool(terminated or truncated)\n",
    "        return obs, reward, done, info\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected env.step() return signature\")\n",
    "\n",
    "def find_checkpoint(model_dir, requested_episode=None):\n",
    "    pths = sorted(glob.glob(os.path.join(model_dir, '*.pth')))\n",
    "    if not pths:\n",
    "        raise FileNotFoundError(f'No .pth checkpoints found in {model_dir}')\n",
    "    if requested_episode is not None:\n",
    "        ep_str = str(requested_episode)\n",
    "        for p in reversed(pths):\n",
    "            name = os.path.basename(p)\n",
    "            if f'_ep{ep_str}' in name or f'ep{ep_str}' in name or f'_episode{ep_str}' in name:\n",
    "                return p\n",
    "        print(f'Warning: requested episode {requested_episode} not found; falling back to latest checkpoint.')\n",
    "    return max(pths, key=os.path.getmtime)\n",
    "\n",
    "# Paths\n",
    "merge_model_dir = os.path.join(path_HW5, 'Models', '1_Models_merge', 'Models_Run_1')\n",
    "videos_dir = os.path.join(path_HW5, 'Videos')\n",
    "os.makedirs(videos_dir, exist_ok=True)\n",
    "\n",
    "# Choose checkpoint; set requested_episode to integer if desired\n",
    "requested_episode = None\n",
    "ckpt_path = find_checkpoint(merge_model_dir, requested_episode=requested_episode)\n",
    "print('Using checkpoint:', ckpt_path)\n",
    "\n",
    "# Build env (no render_mode required for state-based evaluation)\n",
    "env_name = 'merge-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# Instantiate or reuse Agent\n",
    "try:\n",
    "    agent  # reuse if present\n",
    "    print('Re-using existing `agent` instance.')\n",
    "except NameError:\n",
    "    obs_sample = _unpack_reset(env.reset())\n",
    "    state_size = int(np.prod(getattr(obs_sample, 'shape', (obs_sample.size if hasattr(obs_sample,'size') else 1))))\n",
    "    action_size = env.action_space.n if hasattr(env.action_space, 'n') else env.action_space.shape[0]\n",
    "    agent = Agent(state_size, action_size, 'linear', seed=11)\n",
    "    print('Instantiated Agent for evaluation (state-based).')\n",
    "\n",
    "# Load checkpoint robustly\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "loaded = False\n",
    "state_dict = None\n",
    "if isinstance(ckpt, dict):\n",
    "    for key in ('qnetwork_local_state_dict', 'model_state_dict', 'state_dict', 'qnetwork_state_dict'):\n",
    "        if key in ckpt:\n",
    "            state_dict = ckpt[key]\n",
    "            break\n",
    "    if state_dict is None and any(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
    "        state_dict = ckpt\n",
    "else:\n",
    "    state_dict = ckpt\n",
    "\n",
    "if state_dict is not None:\n",
    "    try:\n",
    "        agent.qnetwork_local.load_state_dict(state_dict)\n",
    "        if hasattr(agent, 'qnetwork_target'):\n",
    "            try:\n",
    "                agent.qnetwork_target.load_state_dict(state_dict)\n",
    "            except Exception:\n",
    "                pass\n",
    "        loaded = True\n",
    "        print('Loaded checkpoint into agent.qnetwork_local (and target if compatible).')\n",
    "    except Exception as e:\n",
    "        print('Failed to load state_dict into agent networks:', e)\n",
    "\n",
    "if not loaded:\n",
    "    print('Warning: checkpoint was not loaded automatically. You may need to adapt this cell to your saved checkpoint format.')\n",
    "\n",
    "# Evaluation + record\n",
    "n_eval_episodes = 3\n",
    "eval_eps = 0.01\n",
    "\n",
    "def make_record_env_state(env_name, outdir):\n",
    "    try:\n",
    "        be = gym.make(env_name, render_mode='rgb_array')\n",
    "    except Exception:\n",
    "        be = gym.make(env_name)\n",
    "    try:\n",
    "        return gym.wrappers.RecordVideo(be, outdir, episode_trigger=lambda _: True)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return gym.wrappers.Monitor(be, outdir, force=True)\n",
    "        except Exception:\n",
    "            return be\n",
    "\n",
    "for ep in range(1, n_eval_episodes + 1):\n",
    "    rec_env = make_record_env_state(env_name, videos_dir)\n",
    "    obs = _unpack_reset(rec_env.reset())\n",
    "    done = False\n",
    "    ep_reward = 0.0\n",
    "    while not done:\n",
    "        try:\n",
    "            action = agent.act(np.asarray(obs).ravel(), eps=eval_eps)\n",
    "        except Exception:\n",
    "            with torch.no_grad():\n",
    "                s = torch.from_numpy(np.asarray(obs).ravel()).float().unsqueeze(0).to(device)\n",
    "                qvals = agent.qnetwork_local(s)\n",
    "                action = int(torch.argmax(qvals, dim=1).item())\n",
    "        step_res = rec_env.step(action)\n",
    "        obs, reward, done, info = _unpack_step(step_res)\n",
    "        ep_reward += reward\n",
    "    print(f'[Merge Eval] episode {ep} reward: {ep_reward:.2f}')\n",
    "    try:\n",
    "        rec_env.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Display latest video\n",
    "video_files = []\n",
    "for ext in ('*.mp4', '*.avi', '*.mkv'):\n",
    "    video_files.extend(glob.glob(os.path.join(videos_dir, ext)))\n",
    "if video_files:\n",
    "    latest_video = max(video_files, key=os.path.getmtime)\n",
    "    print('Displaying:', latest_video)\n",
    "    display(Video(latest_video, embed=True))\n",
    "else:\n",
    "    print('No recorded video found in', videos_dir)\n",
    "\n",
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6417f8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated highway_agent for training (state-based).\n",
      "Ep 10\tAvg100 9.49\tEps 0.951\n",
      "Ep 10\tAvg100 9.49\tEps 0.951\n",
      "Ep 20\tAvg100 9.25\tEps 0.905\n",
      "Ep 20\tAvg100 9.25\tEps 0.905\n",
      "Ep 30\tAvg100 8.09\tEps 0.860\n",
      "Ep 30\tAvg100 8.09\tEps 0.860\n",
      "Ep 40\tAvg100 8.41\tEps 0.818\n",
      "Ep 40\tAvg100 8.41\tEps 0.818\n",
      "Ep 50\tAvg100 8.60\tEps 0.778\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep50.pth\n",
      "Ep 50\tAvg100 8.60\tEps 0.778\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep50.pth\n",
      "Ep 60\tAvg100 8.56\tEps 0.740\n",
      "Ep 60\tAvg100 8.56\tEps 0.740\n",
      "Ep 70\tAvg100 8.75\tEps 0.704\n",
      "Ep 70\tAvg100 8.75\tEps 0.704\n",
      "Ep 80\tAvg100 8.43\tEps 0.670\n",
      "Ep 80\tAvg100 8.43\tEps 0.670\n",
      "Ep 90\tAvg100 8.10\tEps 0.637\n",
      "Ep 90\tAvg100 8.10\tEps 0.637\n",
      "Ep 100\tAvg100 8.13\tEps 0.606\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep100.pth\n",
      "Ep 100\tAvg100 8.13\tEps 0.606\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep100.pth\n",
      "Ep 110\tAvg100 8.00\tEps 0.576\n",
      "Ep 110\tAvg100 8.00\tEps 0.576\n",
      "Ep 120\tAvg100 8.49\tEps 0.548\n",
      "Ep 120\tAvg100 8.49\tEps 0.548\n",
      "Ep 130\tAvg100 9.25\tEps 0.521\n",
      "Ep 130\tAvg100 9.25\tEps 0.521\n",
      "Ep 140\tAvg100 9.32\tEps 0.496\n",
      "Ep 140\tAvg100 9.32\tEps 0.496\n",
      "Ep 150\tAvg100 9.29\tEps 0.471\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep150.pth\n",
      "Ep 150\tAvg100 9.29\tEps 0.471\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep150.pth\n",
      "Ep 160\tAvg100 10.03\tEps 0.448\n",
      "Ep 160\tAvg100 10.03\tEps 0.448\n",
      "Ep 170\tAvg100 10.42\tEps 0.427\n",
      "Ep 170\tAvg100 10.42\tEps 0.427\n",
      "Ep 180\tAvg100 11.58\tEps 0.406\n",
      "Ep 180\tAvg100 11.58\tEps 0.406\n",
      "Ep 190\tAvg100 12.12\tEps 0.386\n",
      "Ep 190\tAvg100 12.12\tEps 0.386\n",
      "Ep 200\tAvg100 12.96\tEps 0.367\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep200.pth\n",
      "Training finished — elapsed(s): 127.11877989768982\n",
      "Ep 200\tAvg100 12.96\tEps 0.367\n",
      "Saved checkpoint to C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep200.pth\n",
      "Training finished — elapsed(s): 127.11877989768982\n"
     ]
    }
   ],
   "source": [
    "# CELL 12 – Train highway-fast-v0 (State)\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "env_name = 'highway-fast-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# Hyperparameters\n",
    "n_episodes = 200\n",
    "max_t = 800\n",
    "eps_start, eps_end, eps_decay = 1.0, 0.01, 0.995\n",
    "save_every = 50\n",
    "\n",
    "# derive sizes\n",
    "obs_sample = _unpack_reset(env.reset())\n",
    "state_size = int(np.prod(getattr(obs_sample, 'shape', (obs_sample.size if hasattr(obs_sample,'size') else 1))))\n",
    "action_size = env.action_space.n if hasattr(env.action_space, 'n') else env.action_space.shape[0]\n",
    "\n",
    "try:\n",
    "    highway_agent\n",
    "    print('Re-using existing highway_agent.')\n",
    "except NameError:\n",
    "    highway_agent = Agent(state_size, action_size, 'linear', seed=11)\n",
    "    print('Instantiated highway_agent for training (state-based).')\n",
    "\n",
    "hw_model_dir = os.path.join(path_HW5, 'Models', '2_Models_fastHighway', 'Models_Run_1')\n",
    "os.makedirs(hw_model_dir, exist_ok=True)\n",
    "\n",
    "scores = []\n",
    "scores_window = deque(maxlen=100)\n",
    "eps = eps_start\n",
    "t0 = time.time()\n",
    "\n",
    "for i_episode in range(1, n_episodes + 1):\n",
    "    obs = _unpack_reset(env.reset())\n",
    "    ep_reward = 0.0\n",
    "    for t in range(max_t):\n",
    "        try:\n",
    "            action = highway_agent.act(np.asarray(obs).ravel(), eps=eps)\n",
    "        except Exception:\n",
    "            action = int(np.random.choice(np.arange(action_size)))\n",
    "        step_res = env.step(action)\n",
    "        obs, reward, done, _ = _unpack_step(step_res)\n",
    "        ep_reward += reward\n",
    "\n",
    "        if hasattr(highway_agent, 'step'):\n",
    "            highway_agent.step(np.asarray(obs).ravel(), action, reward, np.asarray(obs).ravel(), done)\n",
    "        else:\n",
    "            try:\n",
    "                highway_agent.memory.add(np.asarray(obs).ravel(), action, reward, np.asarray(obs).ravel(), done)\n",
    "                if len(highway_agent.memory) > BATCH_SIZE:\n",
    "                    highway_agent.learn(highway_agent.memory.sample())\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    scores.append(ep_reward)\n",
    "    scores_window.append(ep_reward)\n",
    "    eps = max(eps_end, eps_decay * eps)\n",
    "\n",
    "    if i_episode % 10 == 0:\n",
    "        avg100 = sum(scores_window) / len(scores_window) if scores_window else 0.0\n",
    "        print(f'Ep {i_episode}\\tAvg100 {avg100:.2f}\\tEps {eps:.3f}')\n",
    "\n",
    "    if i_episode % save_every == 0 or i_episode == n_episodes:\n",
    "        ckpt = {}\n",
    "        if hasattr(highway_agent, 'qnetwork_local'):\n",
    "            ckpt['qnetwork_local_state_dict'] = highway_agent.qnetwork_local.state_dict()\n",
    "        if hasattr(highway_agent, 'qnetwork_target'):\n",
    "            ckpt['qnetwork_target_state_dict'] = highway_agent.qnetwork_target.state_dict()\n",
    "        if hasattr(highway_agent, 'optimizer'):\n",
    "            try:\n",
    "                ckpt['optimizer_state_dict'] = highway_agent.optimizer.state_dict()\n",
    "            except Exception:\n",
    "                pass\n",
    "        fname = os.path.join(hw_model_dir, f'checkpoint_highway_state_ep{i_episode}.pth')\n",
    "        torch.save(ckpt, fname)\n",
    "        print('Saved checkpoint to', fname)\n",
    "\n",
    "print('Training finished — elapsed(s):', time.time() - t0)\n",
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db2a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aec823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e3d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6a44f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using checkpoint: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\2_Models_fastHighway\\Models_Run_1\\checkpoint_highway_state_ep200.pth\n",
      "Loaded highway checkpoint into agent.\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "highway-fast eval ep 1 reward 22.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "highway-fast eval ep 2 reward 20.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\rl-video-episode-0.mp4\n",
      "highway-fast eval ep 3 reward 20.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 13 – Load & Evaluate highway-fast-v0 (State)\n",
    "hw_model_dir = os.path.join(path_HW5, 'Models', '2_Models_fastHighway', 'Models_Run_1')\n",
    "videos_dir = os.path.join(path_HW5, 'Videos')\n",
    "os.makedirs(videos_dir, exist_ok=True)\n",
    "requested_episode = None\n",
    "\n",
    "def pick_checkpoint(dirpath, requested_episode=None):\n",
    "    files = sorted(glob.glob(os.path.join(dirpath, '*.pth')))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No checkpoint files in {dirpath}')\n",
    "    if requested_episode is None:\n",
    "        return max(files, key=os.path.getmtime)\n",
    "    ep_str = str(requested_episode)\n",
    "    for p in reversed(files):\n",
    "        if ep_str in os.path.basename(p):\n",
    "            return p\n",
    "    print('Requested episode not found, falling back to latest.')\n",
    "    return max(files, key=os.path.getmtime)\n",
    "\n",
    "ckpt = pick_checkpoint(hw_model_dir, requested_episode)\n",
    "print('Using checkpoint:', ckpt)\n",
    "\n",
    "env = gym.make('highway-fast-v0')\n",
    "obs_sample = _unpack_reset(env.reset())\n",
    "state_size = int(np.prod(getattr(obs_sample, 'shape', (obs_sample.size if hasattr(obs_sample,'size') else 1))))\n",
    "action_size = env.action_space.n if hasattr(env.action_space, 'n') else env.action_space.shape[0]\n",
    "agent_hw = Agent(state_size, action_size, 'linear', seed=11)\n",
    "\n",
    "ckpt_loaded = torch.load(ckpt, map_location=device)\n",
    "state_dict = None\n",
    "if isinstance(ckpt_loaded, dict):\n",
    "    for key in ('qnetwork_local_state_dict','model_state_dict','state_dict'):\n",
    "        if key in ckpt_loaded:\n",
    "            state_dict = ckpt_loaded[key]\n",
    "            break\n",
    "    if state_dict is None and any(isinstance(v, torch.Tensor) for v in ckpt_loaded.values()):\n",
    "        state_dict = ckpt_loaded\n",
    "else:\n",
    "    state_dict = ckpt_loaded\n",
    "\n",
    "if state_dict is not None:\n",
    "    try:\n",
    "        agent_hw.qnetwork_local.load_state_dict(state_dict)\n",
    "        if hasattr(agent_hw, 'qnetwork_target'):\n",
    "            try:\n",
    "                agent_hw.qnetwork_target.load_state_dict(state_dict)\n",
    "            except Exception:\n",
    "                pass\n",
    "        print('Loaded highway checkpoint into agent.')\n",
    "    except Exception as e:\n",
    "        print('Failed to load:', e)\n",
    "\n",
    "# Evaluate and record\n",
    "episodes = 3\n",
    "for ep in range(episodes):\n",
    "    rec_env = gym.wrappers.RecordVideo(gym.make('highway-fast-v0', render_mode='rgb_array'), videos_dir, episode_trigger=lambda _: True)\n",
    "    obs = _unpack_reset(rec_env.reset())\n",
    "    done = False\n",
    "    ep_r = 0.0\n",
    "    while not done:\n",
    "        action = agent_hw.act(np.asarray(obs).ravel(), eps=0.0)\n",
    "        res = rec_env.step(action)\n",
    "        obs, reward, done, info = _unpack_step(res)\n",
    "        ep_r += reward\n",
    "    print(f'highway-fast eval ep {ep+1} reward {ep_r:.2f}')\n",
    "    try:\n",
    "        rec_env.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Show latest video\n",
    "cands = sorted(glob.glob(os.path.join(videos_dir, '*.mp4')))\n",
    "if cands:\n",
    "    display(Video(cands[-1], embed=True))\n",
    "else:\n",
    "    print('No video recorded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e7eac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN train ep 10 total_reward 20.94\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_20.pth\n",
      "CNN train ep 20 total_reward 34.06\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_20.pth\n",
      "CNN train ep 20 total_reward 34.06\n",
      "CNN train ep 30 total_reward 17.19\n",
      "CNN train ep 30 total_reward 17.19\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_40.pth\n",
      "CNN train ep 40 total_reward 17.20\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_40.pth\n",
      "CNN train ep 40 total_reward 17.20\n",
      "CNN train ep 50 total_reward 37.24\n",
      "CNN train ep 50 total_reward 37.24\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_60.pth\n",
      "CNN train ep 60 total_reward 35.87\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_60.pth\n",
      "CNN train ep 60 total_reward 35.87\n",
      "CNN train ep 70 total_reward 14.52\n",
      "CNN train ep 70 total_reward 14.52\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_80.pth\n",
      "CNN train ep 80 total_reward 14.82\n",
      "Saved C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_cnn_highway-fast-v0_local_80.pth\n",
      "CNN train ep 80 total_reward 14.82\n"
     ]
    }
   ],
   "source": [
    "# CELL 14 – Train Highway-fast-v0 (CNN observation) — robust reset/render & safe config\n",
    "env_name = 'highway-fast-v0'\n",
    "\n",
    "# Create env with render support; avoid unsupported observation types\n",
    "try:\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "except Exception:\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "# Apply only safe config keys\n",
    "cfg = {\"policy_frequency\": 5}\n",
    "if hasattr(env, 'configure'):\n",
    "    try:\n",
    "        env.configure(cfg)\n",
    "    except Exception:\n",
    "        try:\n",
    "            env.unwrapped.config.update(cfg)\n",
    "        except Exception:\n",
    "            pass\n",
    "else:\n",
    "    try:\n",
    "        env.unwrapped.config.update(cfg)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Reset before calling render (OrderEnforcing requires this)\n",
    "res = env.reset()\n",
    "if isinstance(res, tuple) and len(res) >= 1:\n",
    "    _obs = res[0]\n",
    "else:\n",
    "    _obs = res\n",
    "\n",
    "# Safe initial render (fallback to zeros if necessary)\n",
    "try:\n",
    "    sample_frame = env.render()\n",
    "    if sample_frame is None:\n",
    "        sample_frame = np.zeros((84,84,3), dtype=np.uint8)\n",
    "except Exception:\n",
    "    sample_frame = np.zeros((84,84,3), dtype=np.uint8)\n",
    "\n",
    "# Create CNN agent (agent.get_screen will handle resizing)\n",
    "action_size = env.action_space.n\n",
    "agent_cnn = Agent(state_size=int(np.prod((3,84,84))), action_size=action_size, network_type='cnn', seed=11)\n",
    "\n",
    "# Short train/fine-tune loop (SAVE CHECKPOINTS)\n",
    "model_dir_cnn = os.path.join(path_HW5, 'Models', '4_Models_CNN_merge', 'Models_Run_1')\n",
    "os.makedirs(model_dir_cnn, exist_ok=True)\n",
    "n_episodes = 80\n",
    "max_t = 600\n",
    "eps = 1.0\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.995\n",
    "\n",
    "for i_episode in range(1, n_episodes + 1):\n",
    "    # reset at start of each episode (robust to gym/gymnasium)\n",
    "    res = env.reset()\n",
    "    if isinstance(res, tuple) and len(res) >= 1:\n",
    "        _obs = res[0]\n",
    "    else:\n",
    "        _obs = res\n",
    "\n",
    "    # get initial frames safely (reset ensures render allowed)\n",
    "    try:\n",
    "        last = agent_cnn.get_screen(env.render())\n",
    "        current = agent_cnn.get_screen(env.render())\n",
    "    except Exception:\n",
    "        last = torch.zeros((1, 3, 80, 80))\n",
    "        current = last.clone()\n",
    "\n",
    "    obs = current - last\n",
    "    total_reward = 0.0\n",
    "\n",
    "    for t in range(max_t):\n",
    "        action = agent_cnn.act(obs, eps)\n",
    "        step_res = env.step(action)\n",
    "\n",
    "        # Support both gym and gymnasium step signatures\n",
    "        if len(step_res) == 5:\n",
    "            _, reward, terminated, truncated, _ = step_res\n",
    "            done = bool(terminated or truncated)\n",
    "        elif len(step_res) == 4:\n",
    "            _, reward, done, _ = step_res\n",
    "        else:\n",
    "            # unknown signature: stop safely\n",
    "            done = True\n",
    "            reward = 0.0\n",
    "\n",
    "        total_reward += float(reward)\n",
    "\n",
    "        # attempt to update using rendered frames; if render fails use fallback update\n",
    "        try:\n",
    "            last = current\n",
    "            current = agent_cnn.get_screen(env.render())\n",
    "            nxt = current - last\n",
    "            agent_cnn.step(obs.cpu().numpy(), action, reward, nxt.cpu().numpy(), done)\n",
    "            obs = nxt\n",
    "        except Exception:\n",
    "            # fallback learning call without frames\n",
    "            try:\n",
    "                dummy_state = np.zeros((agent_cnn.own_qnet_local.net[0].in_features,), dtype=np.float32)\n",
    "                agent_cnn.step(dummy_state, action, reward, dummy_state, done)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    eps = max(eps_end, eps * eps_decay)\n",
    "\n",
    "    if i_episode % 20 == 0 or i_episode == n_episodes:\n",
    "        fname = os.path.join(model_dir_cnn, f'checkpoint_cnn_{env_name}_local_{i_episode}.pth')\n",
    "        try:\n",
    "            torch.save(agent_cnn.qnetwork_local.state_dict(), fname)\n",
    "            print('Saved', fname)\n",
    "        except Exception as e:\n",
    "            print('Could not save checkpoint:', e)\n",
    "\n",
    "    if i_episode % 10 == 0:\n",
    "        print(f'CNN train ep {i_episode} total_reward {total_reward:.2f}')\n",
    "\n",
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "225ce135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CNN checkpoint: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\4_Models_CNN_merge\\Models_Run_1\\checkpoint_highway_cnn_ep50.pth\n",
      "Loaded checkpoint into CNN local network (strict=False).\n",
      "Missing keys: []\n",
      "Unexpected keys: []\n",
      "Loaded checkpoint into CNN local network (strict=False).\n",
      "Missing keys: []\n",
      "Unexpected keys: []\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-0.mp4\n",
      "CNN eval ep 1 reward 4.785515181744634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-1.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-1.mp4\n",
      "CNN eval ep 2 reward 27.543662955874144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-2.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-2.mp4\n",
      "CNN eval ep 3 reward 25.875144191901796\n",
      "Displaying: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\cnn_eval-episode-2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <video alt=\"eval\" autoplay loop controls style=\"height: 220px; width: 860px;\">\n",
       "            <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAa+VtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzE5MiBjMjRlMDZjIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyNCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTUgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAbmZYiEABL//vet34FM8+JWu6Vzi0y6uUND1R9sJ0mvWkgYAAADAAADAABc+wbTW0geDviOAAAE8v9MP7+gAU0h/G3p0Ybd+uQlpSaSYikkKbz+YxVvKbT/5J4sQCAe82AuBWiyzeGXgrJ2WCm2IvM9Sw5Nf1X7n/knjuC++AAAB9EheQ0P/7D1OEh0Z0IezPGBODMbIoZKqfjRurfMrcJAxZcOUSNepErzxrmRdRys0YCRrVJHqbCzXJV72VcVodGIHltGVnByxTzAJLNthoCQCOPOZ873t8nXkI491AM+B5/so/gAcLxf83gpA0+VaOVqwuin9VNPCp+p2Z+TTAKQ5g8jphW1yD/mrrYYHq2rl23s/jVy5xECJufrJ0voZpUKSKSZddDVv0EIjVBdGoT6TacKASyUsey6rC6/QN35/oVetytzdEiEerGSGThClzCx/rVhcF2V9frEtwc+lYji75IHxj6/FCLS/RjTmYixZUm28KMjc4OfkfbDJ3mQEGFpY7/ElnN/PaCrCSyLuyEHATOkMN2M01In7PiE7bL7QqbK7kCKxzn0U4KkJr/E44Mph451QsHnkpXql4dZo+YtpVTnZO5uf/0DfCOsx1qYIRo+l9vPF+2aYyjd0Z8aPc2iYI9HdoMH+NvTHrEG+lhqQFjdwj/Ukt0uA3mR7sYSBBoz/zSUpf+iiNWuVwd0GeFiJZ5I4pRc2sR5RfW46/s1HbDTRxL2F6dv5kZ5YWWxmQzVxubwdoQtl7E2IYhNDEr3bFK+AXCiLRAU8VYqL9zz5QAOw+QF9/5kubY8ZrjaLBA96iT38OEZpqNL/p3XJJrdA/hDFlAT26EbWOIMx/x0DDeqDLkqiN+VMxgmSj1h+zn9WnMi5uY7LZCRiac5U/syCl3RVSVSV4hhHjOu7ZoT/M+1jHn0hV4AVUNw73zSmFH/n7mtb/7v347YgO0drY3ml7EnnBORrVAf+Qn0c6ElrtKuKGGjklMGRU9qvTKCBPQR4DYRL0Ma2CyVXHDebPVk3wS27pnpe9xEMw9b7pl5x8c13ho0yE8o1ctf3ItRr+MbbOdjdIraljL80W3nZeNTpMaoQNyA978/em28Z7e8jN+YAH/Cgklso4j4g/+n4ABuczzD7ghm5lf7L0XEJDFCmMVfsBn155r+WAcSvSb35dR2oUVgBUS8Yy87WuKKr5gtzPUU6f4DovmJjxJN5gyy8y49Gqa/Na9+vCcUHFub6H7UBiDXAdjQfsy6e0vKUJ/gsGMDGXuCzn/SWoBIoZSEd1xN4cKA4eOCxYzpwDetY6UvFdqj4Cl06kMwxpPfNPL3dktrmGh5+j+OfavUlUpobZSnZ8q56oPhpmj0o743C8ScvjSx77Puo/PRGCtowFve4y92gqG1vjWtmOyi5vb5uOFbzoKs3HEJnfBIKbn/j0gwEn6KmJV/oafjbZadBhk3NeYFci0ezGDRkRdr/nbIZ3f3io1o/cBaVke8lLl0ECMtVe8ecMISxWuQ8P/KejIjp7ElkjUwMFi14jZEP1PCqUs8rFNKdL+6tf5PJasWqz3MNsaTk6T8/Ad68AkAp5JMQJWrivjTkRUj997vFa0RuKXIWj7D3g/wMhlWM8OSA1jsYvpfgJ+IS9BpLcfbYc0SqDIUPA9AqTenlbZ3Aw9Tfw7rEYSlVCh4HoGGfsEBf41ccvQaS3MMbpJ63UrSMpjGcUZ5MsN92Fax/iRTfw7ZngIDjIpFw6RqM5q3qIC/9AOQ9BpLdtF6zkH2S+RSLh0jUZ2OrDWzUj/Eim/h27QO/spiKmMZxRndy5upZ51JucDr8k8p/M6/3Vh4oLet/c9rMc67DFJ+f3QOvyTyoDpP/Gw/VmJOhftcKovVZvIDs/qk5vQhf0tfr72dkQUtfr+TcxS/trFEXxyOf5FlopltyyhUCkKxSvQJUZz1PMYEqMzh7EJp1slYlBo7QCyMFiBzy/fGRtBzF8bsDBV44+sizC/mT2FYcD0Q+QuBm/TvHCwq1fYlexKXsns2PCJExW/aKv8oremlQZ5L4Cxb4oP1M/EyBJMn2b7Sr5ahVKqSDCAVl8XgkmUAx1uIBm3Qibe4Dx9bylywv8HkrGdbRkmZ3L2ISCgk/38CFJAL64+rUf9ohjZsQypkmwCVkCCcdVeJ4GoH0urBS1KVtfZbGNYOCV+36fTCXSHlf6GiYZxDegAqXbEsX2t1KwZtFA7L7ZBeUW4/YkaMnGG0hFHLitag49vNNvX8o9y0ceDie2D0Ta+fu//i43Ud8jzaWe1L0tMOO5TaXv0dwLsxgtyyq8oBBQlZcqlbzmdvaG7kKseJzyV2qonpjLyTtpgPN4Nac3GEABOwbkEAAALJQZohbEE//rUqgBGHEDaduTrvIjrAD9gntkH/0Rr0Pbn6ENlqXEBBs4JXlAasQSU0kwYqtyIpoDOvMFdIcJchgXOj0phwjF8xN8VwFewHlXhD+myyOvKsGDu3t18fT7N8ZZPv//6PaqG7QqyPkI3HfkUTra3X7+YoAyvXtTu7GcdlMk6kWL1hh+xlgBmeb0+B4QaoMYbCXLnRyqjRt2m6HbCUk2Cju0HW0f7mC66cbqRrgsZDQv4getCQfrcYepKi0BO7oiXML2nXlPt9Egqmtiq8rtBh5O3XKYjlikKg+/jY7aKMouMiJ2BElQ1+jD0kIf1t8198NPLgxXOPINcVFt+m6Zh50Sk8QBhaJe7GUmB+94Rt7nK0tIJ6ZzdrM43fSwyey38D4MuGWcyuHl9xgfrFNIVc9LuOam/pbCzrAK2UpKdIY7vYMtsxKoZazbLtHFLO96YMyPm9L6gDaULnDnf3fTFq8XOflTSDI2pxzZerE0uHDeKON2ssPGcg4M4OrUMpmCjEm+ngE/Q/qLYz7ClxBUzLLbmKC1by25ExvdpegmgN0p+C98gtIx6E7sG4Q507AQocbc4ptur2cT5OgInijm+NseMJpexagO2m1Er1ywLzrzWXk+HZPsRA0DJQ+QK2RvgbgiI1j53jBckQAPedk19XWLvdpreukF2Il4Qur3YUEwqm4uFq5QsTd6WcGfpZroBvAsoHkJW9lpQ6JE5E5Jm1Wgu/zXx8r5douVxoQBJeRVn7Xj0+2oFlSzJ1UX9YQbV8H0ucFz4EY/lDKnEFDmijBtTpltcGQI64NA5NGB/X8B9ZcfHjn8ZEtTch6BQpv+Nlwn/5WOe/4ZSBuQD+Psm7jZhu48GpWZ12Hpck6rWJiPAc55YG5z+M+YJTtxIy2GXMwSY0spev0ayccRJtqm7JAED8IUxHCNIgIWp1lAuCsEwRWygAAAUXQZpDPCGTKYQT//61KoDDmh0YSWWAAXWYa//y5g2Eb5NIl+jHWS0e+gqS0rP4QIViGmh8gUq+MA8aqU0RzuAHWOu7ED46fL3Kmc4sz+M9H1Mjdreiss6v63p5MN/gBzOB8yHrFR/xRlIzZhbzQuaL0hXFcL6xK7ssaGfNwPQQnfp6mwqJQ9WH8w2gUwgC6zbh0CkoEspy7lm3LtBzgDeUmxKdAmwlclgEp5f8p7eEXaKQSIoDse+J7VAReElA2UimGqfZ7hFXtE79awEd06fzQV0E4eWvmUlT125J9IjQgtO4H9AEr4dsxHChyRbziuvPGxRNDjGacOsuSQ8L8qS+yiZggQbMwKFxBitN//590nzHYcnK24imJ8olwakdlyG2DS00yXPyaMKkmTp14rdRNLRb95AgRTX2VIwlXYKWogDosS5RBj1JDV3juo5c1bcrE6VLHsIXqQ2YHIC1UUsd+LN8ld+joxnVvl9cWkxtHoRCQRVVegtpi234z6xaKhtlAUDt1ECWhT4bEHYp8VpXsLXalkajMsgwi843IZU+H3aCKkCRJm893oYMOvU8qNk+JIXzBxu+sVNPomcCOJ3JkitGZf/3Jqpku6fSgoNV22DnZzPwyydY4Cp6QbDiHVIMX6pRGSMkXCu5sjIw9fwZPgYOUT0tcXHoXH/hyLKGT0VlgJAhLoebOY+FIjhjEzlgqwJA6Yoco5anfHJtZkLKAyBoVElahHWwoik1Ioha6Q8NmVcJq5WJ8YSXYdw8sEx+nSSR+0Y6IryA8fo12PYZi6yByv30PTUHPUB5nVV3a34G6LEOjYCmfI1+VUbzlzN3quBLMI1GqCy3sY/uqSTlXg9wiDHavlfW+L0vBIkqHc8MnUwu+hHZ2ye+/fA3ANUDx7BhGAyqGabfIJ8v4t92ghvoqqOIP6dftfrxwpkbQD0BC2mslqqXKsOSAVE4+8PLCt/iQ2gDoUJ9XJg1540rBEyknxG+4COqFSFMxYCdjrPa42GXoG0hqBC4lOTCEDSQ0YWbgtKref42knxlcT4viJPE+kqYiBbAwHow/49nevPWFXCdKhUw50z+urSXtR6NLCk5ImDFFhfkfWB3OwNKrP317RxymnBHsly3DcJZOEwmerbw9Qr63NPruHWwjBSUo3cPk20AOGGbf7W9OE79GHV6HX+3jZKUfUfaW2Ss1Zyh+Z7mMAN0MGU5Znzv1TRvQSNGfWWa0XOhJS9mBlvNSYnGUfglI5/394LCYqGUmkLM5SEuR4dvz3YLt9cGd7ehzRYPX7cemIcx6HKzIc3Z1sIhkQ0HY1IUgkpzch19iG2l+cGQvzjDR+waw/bZRLrLz/TTasxiAzuTMT/jYkfKwml6P82AEFRHOM7oqHLXUygAv6NFK040Qe9SLz65ddZElmxG4B9ax5VEkxD1VsGjTEmHEZt8j/Hvg59zL4/nOguY/Hmh07WRtRgPQl7cZPxwPKGarP1YhuIFsP9o9plpvNqPS5MWfxjmSY9XhAGhq2UEukXeV89HR5Z+Fx+N9oQyeAPFEXxbjK3wXx63TI3EN5BO4Vqv70U7uPaTfM/zIwzNRp+HuBFuhh4DwL8BjLPcFqDL2WZ3m2fw6uD91Y+TBbI57dEps9MHybep/BPAx1lMfYHqnaURoJKHmBLdbewC0mIh0WgiEIT6SKJxA4JoVDObmV6eaymJU0XQ7mciUYVb73r5R+ddGATKzKBNB4abaplhfAC9gQAAApkBnmJqQS8AHkncg9Esm7A+eUR9FNF1pbNAoNmf1AiZWKfQEeH7f/84ebyAFrWKZI51ANbidQYWONb5fWwkoNoI3gOhcwj9bwUTf4RRKydrJdwEWDIW1725k7teElIsnlG7546eghnEDXA/3G+cgcReGAVOq8EU7ErIeuUZbQAixqwJbXspNJstK7OAbOwz7apozOGhSQZEll7qTEC/cXQKnMcVodwUB2PN5a92HAobudL4uX723dDy0ZFWcCgGhmAVoWIUBVNMKqPCkG/l7Z+ZaS7QJBdooGIY0Evg4hawBW6iglLT/JdSrew72dR0rJPmvqW0GA15u/4PQD5+5IOsIlsybzxHBtqySG6UciVykYruXlXFMBYeyklsFE0fqrqSvza5u6u4XDixi71SrnOV+tMM52HLGm2ep5WwJst/Y5zKGTFWUNm4Az7UZmF38nn5itwEOEbQT6Rtq8wVj6LfBY0EB1Fjw3Qdy7MEpKl/qhwr6n9kkV8ddy6O4RwoImwkuPfAvuF0vsXWcOFq/UkzBpFpAvQMlG43/D0U1PuW8v2hSf55cUCadapWB4uQg6kmgPLYQUNrTOA6A6xi5OcQh2eQ+YiRLjd8y2LYBg0LhWCuTXu9BHxsDr5ojjvU0pMPDRrQqA8acketML42PxLw34gjvH+nVYAe1CFsG+HfybrZB+AZ7xTxRDzBFTpaXAHiYL/tX1PSrgjwLWHwv5vWpEX8vdig4ITaToZxTFFqgPam1/t5I69XT+vOUVNini13TG8BmNi4/08JamoATzz6FYU2kVe9Y8POkoOHS8U9ShQ3rswQdAl/euhwQmH7wcDNNISuJCPlXr+G8DvEi7q+dzcLOk7UCIc8ZjTVxIbYTat+2zbyAgA7oAAAA6FBmmZJ4Q8mUwIJf/61KoDD7GnbfQJmCaRRr/hIjY/TAAADAAADAAADAIt82sjwaF6fAjfTgh6gBJak5Gpak0B9XXiL6roroMRqDd3zvjKggYKRJhv+MAELZKB74TfXwIZJQZggPs7CXZn54T/zX7QG5tlCB66mY9wmhGqhv0FRJdemdIVlH/Whwu17RFHvFZ/xCgHMlyd2+6kI0RmA4+5Kq8zed8L5hw+6WUF+R60/CdbXCQwhf4UGP70ua4j9nb2xZLT2Fcpy7CEiHTHtjSYMdhb+WMFiMUZJ7nspV37SCHqa7eNWjuoWGxWbKmZLfBjtc99FU47JdAV4gQ+i9vqDcM2NeZsWgiyufeSwpq9LXvx/wIuxxi3TXMrETpu5tGn9XTCenwhHy7hgbmGyav4nw/uP42qMFAFycy2ZO6URUwqJjLVdszFWLVi8UmUU0u3ra7d4ehGu+L2tigahrL+kQ0LPuvEJ1fZFguK2sbj5YEVefk2Ej9tXdlz33c9pL4nvrvMqdrMD98Uj9BHyWIdfxIU6RQkzE3OuhyTR7LKjTv6tn/feniIUfHiriPvDwg/Ibwv0kYZ8QsmqOhalRFf3EuB2QHo80REjItJnUF01ByjCt7iyfghSpDEDT0O61ucDtWUTgwK72OkjB1w1BeZRBIOwjj9iyZYC2buMppMBtEz6cMmKDigBH4oKfDcHPWr4kpkBUgPUG88DsceiSSmkcT25bjzuPsoahllCbchjW38uWbQMgBST5I7+1Pi4K+SETuFHBaSIU/fhy1t9WmAIfL21OBjH8I91a2qqBlWc7zUOwUTBjGGJSuQGnh+1fyxSVm4YXrB+FSrykjGNg4NgFh/zU8da9I41OotT3d3so/cFjIiOAkYL4U9x6ikflcdRbaXUOu+v6t/h2Rn9XYxfDbeagirpG++YAHTW79fcV7tetgdU/cdlT95j1BQgaKRy0Y5ztKFOBoehudgFscsFiEx7TjbAUF0icMbsJWrXXTZ/otV9PioLGEUdi7z76l4u6nLkbnadLVZbm+Oy7UFDeHCGO7ENf/kKel6Ii4B3NVGrwigSfKgsqH5BrvRkmLTwaGJ9TYAdQ3QkOTc2GOVJsXmS/O7y/KlkrRLKtoGLRvxRzfizQ+GAvBcDhIo/dia+Qzzk389iNdsrKcTKEiH1TA1MLLeOHY6Ybr3v3YyTIGzgURtDTy21R0go1r599siFW9lK89XzevLrGbVMsAAl4QAAAxJBnoRFETwT/wAVQRfvH1j2WoKlcvSFEbvjrXU3ShrmHePu/gBZfsREYH/6MKKXzk1nOTho/3FMJiQHWiE07LLw1ur51Y2EUfbzMI55Purd0vE0cA7Nq0Wm99AXvpPxfFXTDIMH+dsTM5N0xFLM9ivUv3q/GD82nR/RWmcdU505n43BqL1pKJw1flsgYnaLb7C+q9DaUy5tn04D9O2KI+uoQEDueQf4TUcs1cM8RupoV+szcPAirheJ3a2NAGb5XY2BD1YOzyI+wx+k0HLOjppn8WtqB74Uf8yXC84EftrCR3c2ZobUn0YIe2tSGfcXMBjhAH4TS1p7nrOENFm/dTNJmsDGeWLMi/bzEhkjyCbTjslukNbkl4ZpB/CzzKIfk72fQuFMn3aiIPiLoaZMy6hjXVr8/vlorpoU+K0pE22/CmvL7V311oszHyP6bAfUyqFHD2Ww2TwxQUCUWoiUgducWFSQRUk7et0rAYAC4m11QozdQ1vhOdX8AhkmwdF5rnbgJRrQCEqM+6R2PeIQ1Bgu/2AaCUnJ+VUxbHa2JCy0TA1w27t0SuWuQWSVZgyZfnJjP5a8/LtDbPMDWq4r9xz4Dmp6PnTU3dIxla4nLEOsPOngD3cxeYugHzZKh6xz/+CrEDg4dNf/wlMtY1pGoz959IbVVYLdK63GyfAiMIKKw1cvl6QZ0gCdVHzgHctZxO0p2+YJuuKY26s+pgL+oWIWhTrkQlA/tRcS0MQKZecCcWJEb9Uu4NJ1DdwY4v9FurF8c5xNyAM7zN5Vzml4motxGaRFxKjDvRIhtB/CjOLR5uyhRBhNUOH9OXtuDyBKKIXt6AAr1BBxwkCRdxPSkKOtlvFD3AQEQnNdA/YZdn/4syGncV8JLOJJ6xPON8H+7GCEYjwgfp1MrJfCY5LScKURE3cO4u4YxTj2ESaYOXMNE8fyFBQVQIlo+NE7fwOoOLtlE+sYBZHUoTqfZP1qWY7YahtoUIm/AXXttwO6C7rKZwD1+t7uXwEER5umC9I33mqJB7c2qoaVQFJYAIBapVAAf4EAAAM/AZ6lakEvAB5qiMb8I1t61xhwM+BH/4v8cQAFsw5IJheVj7wce3Rm6MtgTQ3miSlbPol1sWPZci02/knrEb6wPUwdTgdnu390eQJ2+o18CMKVCQRN0jy+Ann/ecePudBUiaTb8GztY+gHsJDbS0HHfW4bXmIjbJF21nAAAAMABPFk9tu0FVIv0+kFe4Zt+3gul//uiiRiZD62ZaODhQ+GsL1J36qABuZkSRFXm3CPzn1VPvbpcgb2M5FbsNURRfMDkb1INymqaajyRF9kSbm2LTbPlmSfftuRb1Xwp22quCy/apN8XfnKveycMNcKqJrVvO5qdyvFYtof+IeYtA+Ek91hGG2koAKLH1sYQ78T4kdTR4MVLwlgAU8gxL+iGJKsK+2qGHmMt4PCUZn2ioTRLaYLxeKhLKC0zJEu1eymYww8PGjJhjYGsWlv0dtovH+0Jt7/G1p1/6/OGpFQtV8Q0/9mJlfcWgasmKLmVJdqyYAzt7mFkZBJAceQG13FRy6zTCa5UZnRQyNTTa0qgoGocqgyzG2ebAwtv+L4XS1d9NBPd/BsLcmlqxFc/WHs7rXm0+Xoh2C0tNYKG1lVBbh60x6x7Iu4bnQf6340vJeZyvvB3trgVO9UDSTxNTk1FT0v008px1YHVCJiLNrv8CXdvuRX7bP4GclqDXiUH5OWs/OiKqki3DC3L/tyP6UA32hgB1xK4ZdVW34/5XjfC7jpj5v32j6VQ8K+bLM0R33Q2eqWy12jYuWkNi7UDP5t8s1NJHWl5k+BDA0F70qBTUPbFlCU65TfTN7uP/wkcejti1nwZnfl+z2+LLFNq1vP5tfugY/JBiid5lcoQfiNbS0pqv+uh9Q05lmenxK56e2o2ATbc1JbY/W3HozT2UiVhTcBBzBDmHr/UTwrKVvuB5aPH+iYRFLKnyUd4+oZNobGfS/IYMYof7ZopOhVdYBjeKX7tRctbEOcv7oeakfdDLgYDURuhozCxQJMoPJxc0qxITG0Hc6k9BXURftM9deDuwqUdkQAWVLO/SvH7U00o3gXF8uzsnjLDYbn6INdyLzP6kMRkrZilfi0Ejs11eQ3La/jPGomDuOKWBemtm1qgCphAAAFoUGap0moQWiZTAgl//61KoARn7GnbfQJmCaRRr/hIjY/TAAAAwAAAwAAAwG2+n5xwR2CASC1aHgUohwEVImn8+JAuBf8f5Eru1F/IGwfrNINkrcAa52N3NXxuUb/vzZoeavyBlVOBdvG8FTtyCTnPc1woPW27CmkNjDN1feSM5e2VjUwU60JRJmTqFq6Ap4Jpa0aj4dsY/3xA7ADIxLIBCO0fy3QPHed5AzIX0doEGOJpiir6Y0+b9Q/tujP+x9DuGvgM/Br9D2sm50hJvgF8u4aQ6h/OsaXp0PPZx0QDpBEZQnx3GIZhCbgF3V3xzffdrUzuMDU0XcWxxh/dUkaNA6/D8DoLazWjkl0pH4p/yGqKGplMywCy4CQDgFQgdo7j0RIkKFKp4t437rtJf8lh2wT1VHV+Lta9eaPsJ7wDRQ7uTHimHS3SRoOB4T4sTz6vurNEfqPuXbDiUPlI0aKjt0+c3sS3VBu8hyissV/CDFzf5WethHK7bOQEN7XaVLkqpe7H1M2AdqpWPopb7L15YNMuhsOqa83Q0T/mybq9IJR6mAhOjJLC+HVu4f716P+o0EVbjAaZUiICCRR5IHtxo9Eug1FUWQumMo60zSqwdgMfVLiadt8N6Y+zAjBqKp8bMQwbf3Ce92s8b902vuT7EcD2kChsnaBkV6A/QoSP2hFSpoEdQa5hymHgviz3fapO0RYo78FILDXAsvhIo/2iRsjfDMa7jFL0PYGJnzjaZRr25iwr4hoKpFWxxVkJLp55fP0KEFGt50312i7tYGm+AByW1cRnxsbVgv29IMbQ01R52gq7/S7pStIJ55YZjELxoFxZLOzzLcVqYx9YJ3wAXTesNTKho93zLM8eLyJqIgzTfU8jDqKV+NpXquakmngEDOa5hHnkCLwJExnxo2TChOZW3+UMHqac3luEoaQMoHF8gRKL45x4xr5eLOXtSV20O20ElLuqTQupMWsCDhnGlqirjb+NUUpCKNXzFRW1X3Cg38JsrRXE1q58LiVwZH6bRlcdYnhRMX6s2bzJwAzwAJIUsXZZCSrgx3UXX31Gbr0h1nPgg8gUYIwmIZ2p2TkgyF6lffw/hi9ZN3z1BCgo4qETcVyiOrMasbaT7I41VoWbyWlmcnQQg/Mv6sxqxndzTDjVWejvmj9wOjfVit2HPpEwOwNz7pOHhxudGCrvnheOKmKoevCrAnkohHByYyWIC0w4IAwnAXpkopWgLby94NXwtwHjf6rA8Gy6JcLHoHKKS5tJLfhSTfjfZFMDPdsOqKT5oCq7FqfTDxkDcABLFwWLxN0Xns9/zQ/dtpx9nRKm95tmj7RnkH4gyK66ZbcIofwnloVCmwO9ONSPlx8BbJwUUgTUDeNgvCBmFFjOYn2v6tms7S4BGq3tFF7lldgDrhIva24T60iatGPoeJT+0x8xerB1LqTizeku7zgPBL8V6oK1rAj7gI2fW031OnqAX+CCYqGwl0z0gS3OFOUz7mAlHNwsAkdrFGRo/8VjT0/lyMzI8bvjFh3o97bJlg8gg4tc0AgJntNujy93l8PrtarTaiPVMU9PbHvJZph7U9KVrByg65SEiJU/M9/392TQFew0hNWDOQ3Sv9EFLmUV2Ir/lwOjsp4r0fiGbNC5WsWK4hE9PUCfZVV5Sc+KXvIKY73SLd0qBlqjlwpWF8wIqt/FiI30H3cbdR4G7igM7TH1cy61+iiGtWcLRaC8Ab9HH2y7eerI4jRUEH6jnJmwarV+xHTE3R1xaCFk/s6B3Ho941DhRVwNo1Je9VkaHTOVMHOcQlp308GxWmdRemEeW8qdLoiysziwfw4xeDc6NmM/QoLVpAPYE4BIKEEkZS/tyrXhVjWxViZ3PI2Wx7i/8vMBNeEvZH11FHTQnrPDFJLoUtlon8u0Hp1ZT1OvVMsDEkAAAPWQZrISeEKUmUwIJ///rUqgBGFEBa5Fa1JR82QiWLddfbpsOu+rHdSfMOFbKbLF/l8XkFdlp4iP4WhhACYS1/5OmX419bw6P2NzhVzt0JuOvEtBWExk6jOhyBzgwAIMrH9PCEKEGv4yP8LiUI+N+HhuSCLQ3tPSZX9G3vwhycbNLXAPiXSxnoUEK/cx+MRZN1rzUsiQ89gHG8YV1Mshpa9m4K7+YWzeGogAAAMCSsjp9jc4x3HMCsN/Yz0liTKSaZB/dV1eLufGDI5bK0a+Yu0XcxhN/dFOybZrDh2eZzO/E2nPnEMhwnv/u3/VbhHx0JhxhT1Cf8WkRn6Fc5y8T7fhQ/fXjiMtQaDfhtDWokJkC+je2wz7HsUfgCAFWk5KpT0zbuApvqWFOIv6KoOYJ5Ae562u4Poc1PgPqACN+jFYZKEshM/TzwRRI9wMu7EIPu1eNTziFintsTWI0Hq1qn0CRwb99vyjl79Z+xvV4Z9XCqAnyxsf8A+QB5W2ui3NJaboQdfG1NGeWbukBPgj8BO+PK1xSbsf5VfLB01rwB2/G9kjpH0qgyduxWAqsXgWKfYK/rh1G1t9iBIeQux3ln9jM++7q1mSdy1mZb5ua+c0ln5p7OLsy0pbJXDYHBnYpSABPB+/OzpEXbZ7W87J+IVf0fLTTDoUABgzFDLF6WFO2+oBjRZomWay2RHp7hU2b29jljGr22uQMO7vrVREDCvSxO20UeqWzLLB63fjvaat5ghiCBavOUJMQsZ30371jLF8GY5KnOny0pLNKvtR83z0160WY1/CwrGhzwO84JwKub7H0Es0lNiUf0U5NU5XQpdlVVdLt6ivOdujDHYzNMd3NfdIdu+pI3rFWAUmxhy+zmF4DvvVVeq26RmbNA/6tpTsjQhCVa2xzKdBcbZZDIvc6ml18y39Lrb1ljN+bRoApCXn3LD0RJF2xchdbZOCAQqVwyJWShXN4YJRenkBRbhcyObCNyzcizZsPSalBpajBWFXnVGgfz711YYFdreRFNQmzkuEszzC09urEsmO+o2Ct7xk/goOomdX0PAABwIK3USJywW2wI526ZFFX98gvC+Wvu2VMEexh4EFV7SJ6d3xxK50Z4+6/Fu16x4z47HW4Q4c/+NJXorwnqfRiIe0jzF9yfDoCIymtOdYa982af+RQViKAAAf4bhfTdJTMEeUIQi0+ma6IemwEEH6A2jlqX39whnrXv9dBd2C3Whjok6aC1VacYKZWftHEXeyXSuE1eXLtf5UXvYcPwQr3t04p4E+lrj9SqS5RyMipB6AAADAA7jUqgMSAAAA/ZBmupJ4Q6JlMFNEwT//rUqgBGftQxY98GtWBGdjk+MsVrLQAAAAwAAAwAAGpFiDo+LCrIsWsoQogM+jx7xrMCCAPXx835q0qdWNaXXHEARG2Ziglo6uMNVcyFgv9Cf98F0bkDtzRPlpOj8Ji+4V5qvvPEwJAdSAnm/wOGh5mbFwEyO/vKA6kaV0Ou9+AP/EEQBfw9GjZvWZkzzGvbCw2c0XT4uSOY2zuCRyHVwt4OSXVgGAp7ovi2AIWD3tCFDu23u7WZQv0j9Ox0C7oKLYKv2jb98CLXTeO4WBcyxWQ+26IAnc8onpSH6Q4wgAYTFKIAhP7P89zIolr87i9nMT+2sGCF4lEjjTtbAEWzigLDgIiGdRRY1bmRIibCQabtaPvVUGs+jXpcNIJ2IyfXXmlvxvSqM0mbdvgHmSDn/OiPfviQ9VRmDVh29gsXUTGpn+pHjxWj+lKaexH2K5IB/N0jatVfoHQtL2gy5CAceiAo7VxIzEXig1KjpQSvA77hZNsE4Vwqq1MgwAHZp/uUZfevqUeKYfV0aJre9Yswlgb9hTpi4wHlSmsW71MV6WwwSWiqnUWqHGQgl6F2rEbuU8gbK1K2gI1OAiKHYZrZmhhwEGK7M8/uZEnm7YSxxhT8rZlxcwIAGt6ZweMSBm4lyijcGKHfrOb2vtm6aE4T+54pzZkMHOdHVHtxxVlcDE1YYCOMPDhHJSeuYXohLMMGptB1zmfiqf20RbZ4CfTa60gCHLwjiB3wMKdaQd1TxKhRSTHgLGHHzriZJd6qceYQm88JcdJ6FzQBUNUhKTF3GPdPH9zuqEwMO/KHB8JUwFeO31cXGOZPmRRVUIREWZnC2p1KfFQR8W2RcscVaD6/0bQGPMHMSZR+G1czJhz4igsoufBRa89N5cZURHoS1ckWgw6fZZZGMocSm3WWDnQHZOq5GyAiDQDkVLYw35fTKAPIO+2ycY9sbLzxvz/0XJEbZypTT61cx0MGoQhEi5F/Qs2Mzg1cGTC75qVvr6avYcbeSXg6mcMjO8c5DPXssrKzbpbhIjUsRLcM/dV0Ld2SB95rT3uIFliJNgs28iMnB5gT8XhcXufYCS/KzJ6kSkpiqna+ZwSbjv3LS958CRP5khvcHKhDwvgc6wIaZy3JiF2yUZmVVK1wTY8DQmnN8Bz2pkao001Oo7l+BiMIImDOrv4kD/XelZegDPALJk7aw4SXhE61MISxFZGjaghtqIMdYRk/C0PDo39erQuCmOU1QdBoQ383HqjJpEAJLzBnzZXn9hIuIabWUjL9T8k+96WKWGNdTqHQDP7bgQ7oPEfOx+oYhLI74YMBDhADBgAAAAwACEtJtoaplgYkAAAPAAZ8JakEvAAiwicV5tWnuR23aVVQAAAMAAAMBaly9PzFMFsQAAAMAoXTwY7VOEts9mZprOQJ46wAJLSiL92ESMu/Su/+bKLBKfKENUlphOb1QoOYS6mn9pXtFu32QYnh2MHwobwC1Rgj92bvzD9d+EhiB2mgiOFq05+q0wbkb080Po/9FV3pBnoOQoOFRWMwtCcic1kmVhlZ67xQTYb2fez6hxEhwv5BGlbCXTxRDg4bCv8nk9Lwo09HmbsXPFJHZn6KWh9Q8tv1WaTkF3pQHQRXO5Phfz5T80RA+1mPVUgadT0Xag4r0T9ZYnhT0N88TqET405NZZmNaEO66J8CL9R7BHBnXEtvm+FwKFwWgYju8IzE0LdkYTFhKVx8tzCZ7T6k4idSppcKzkfjH/fDyyG4vbFPj3P+582ezeUubPY8c4nk+xcx1fXo+iN4KJdkRaAG1IJxrF82SIi4eBFG/qXbYc6Rcq6oqaunhpYyF8+3NJI3lPMI2KL0oSRPjdBkg4PWuyHthy3kENNAtZeumi0Mu/Rgf4vbASm8//4bzdEuz0ApFrH6K8tnbMdQJfjJgr/439VO2wZPFUeqBKvtc4g0YL0bLEOocdvGPksp5dYH0ZqI3Fyau81CFTq9AP2eqEtIzQvkw8gJsTFQfhRObuzUPPmpV0nT4zqOrIwfdiMYBA/hyV8MIIFwYfW+wZvt2picIIAsB7c7SA5jbFkKCjxrWZWZOWYM1FCdr+hAQ4VQjpNBAKLtKW7PxiAFqE7jMDhwWXyPNczDQo92rTCu5gmbVTsBJgwdzD1uVhNORtVbQezIzc4N/wshatp4raT5eW10wBDL6jnRIQOn0s8uc1ydm6w/7IIOcsk+nqzvOjgOwCd5K7R+jHQmyYYX01vfjbTMhtaAriWoyRSMFNuhDtqFL7lAEBTehBe+XY3K0ypHd5sjekM8lbnqfdJskB26zRIS5e9NLbvRPPohWdAz2c6QKqcgTQfRPtuDxljsy7ONvf8wiJFH2NEN+eN5lfZFCsdejxVyDeMe6/SxHbOouzCmq/NVy+oJEZKixxEAc0nrcW4E8BLi7jvAcOJ8ZLvYFap32Y6vTBSpifM/fb3CMJNmcfI6paO6x0XzdBMJFOiONLyoWOWjAGzVkYbsbBXN6tSb+PjKFXc+2YBZHAOl/iwXKkzlcDEd3C4CppnreiqSYhvwmq3CBnCabtR9g9SWRII/m99GhV+d1gZ8O7WfklJbZxGfxSS7zMO/RfLvjATz2WsBC4segAAAXksmPuQP3AAAEqEGbDUnhDyZTAgn//rUqgBGFEOosF0A1qSj5shEsW66+3TYdd9WO71AF/DY1zhyXasDKwxpm19aXAu0crX/j641E79IIAADxHrmyoFKLyKUuIw/2Ee8ttkSbi8Li4VTgnPk7PC4LNDsoWP109aEg+gDSJnyU9m6ZxuQJi6l3ED53ZlBDQqSx6Fzk74YK4MqY6mQLwESRoEC8WkeIfb4X84Dc85Cj3++7B3gV+/sjD/hbXXbd0nCSAVFScdMHStm+QPQpXTyBIHSzWA0QlpeO8ixcv6z5Vp5QTUKmqLT1bk1mXhmywP/YgaiQKYY+wxaHSyyX2SeDIdkb/673BhaETv8LetO12TWNtj/9DYTIu2vevlVf7FLGOMlGahXd3G5rRrkrR8iqedXHV0wwQk90NGLKjY6Ez6OZC4himBnE7IivXWUKCFR4BO7VVQsEU9qN9fre/ntqquRPQo5NU9S0T3SfUgo7tWnYIyOTjrLhK3PEpTOI7mBxJKeiXPOED0eKvDgxnCXt7sVogvlp8pWNqA7vtSy3DLWQigcfbxLOjHu51EWjpwhZCLhvg9Wv8dRz1jYcA8UQyQP67VE1C9m6wAFMXoEJgBVh7xwUIcvIVwPqN/Q/L7VfGH6OdHIjPYzlMSAac0yRK5k6vTjaesZCNzzbJbENqKkEQv6+sUUL2bVpK9vUWBEw0LjMHpqRh3RggG4q6ZuN8ckS/Mvhih3cAzAxtBnVWsHdJMBaMB8XNsJ7P6bwDF4vMvFflXTTo7WIhBcrYJ2b7pxUbmRRE2jJFWzWcwTj87mhyDSNMQjeqryzbTMrBvDRlULj3XOU8nct3aZK4v/Er4N4tdpLbLfjNJeIk3Nud9tJZloRQ7BjQeKgbiTfv+S8IKkTMGkF8JIAYGaFAz+RnR1PYDzCLfS6yDkaS7b4VekDiIuWrCVeV2QHo1IKOBMvw9n5vQlxNiJC+wK6jQ5dkwwR0ZyjDiVXf9XPOp8nTgbdKaS5F5Uo1gopKRUG9v8lgQ0or2imEj6VNfwXWdxnBez/bDdilFvcJhY9ryf7hL1kgQR6rvrEu4BUpvTSvssOXUPzGMA+Onsu1exmf1hYNi4dI1GX0dpWeOGOjH+JFM4v2/6BZoA+RwzqmdTbWfUQmBejwtIlTNi/5pSQnR7dwDt7CzBEyJeABIK1QHRghslQoGlfuetNcOSFX0DAL1NaySMjjsVWcxj8DTPQXbsrhvib2wF0psN6j2zrDHC/4IQGDrKroImfjPJpH7xDQDyI+2n9RPOzcJyiahFjkMb577czSeREF43z6P9cXlcXCIyzDiUVOjpidExwzptLp0VRWkhZR2ziQjhvw8va6FG5VHv3+/tHgdhJE2I14UggEzY8dyGGHslrTkyUOAAtDUIO5WioBfX7Y5YaOqgcQlZrNIqgYl6cMZxxF7T2t3NquTlXDldkrJ0ehINMizTKeGMlPxGBjSDHrpGkBXXUZ2+G98yrKzVnmfwJOtqIeT5JiTr/CmYs6DjCR+lpIOl/FV6V/q81nLLPlP3BdEw5qMQxszJq2pQWoe1P7Hx+Vpl2/9o+921PgGFIVFccAABxmpVAYkAAAAKFQZ8rRRE8E/8ABdqZwZC48cZTVFVSNTFeHAAAAwAAAwAHr7daMsB627y/3x5nnYAADjqWZzXbpat3cSxYaqVQa4kuEo7zjoASrweLRCE068wj0wW0VSDd77TmSm/QIGt20qwzle8VM8QPOZulfR5f0pEHmje1ecRjMTBPIZ6jl3CIV4QloUYI+fQ8xTlUAAVFuY95afOiE6ZErleSjsepbWP5EZ8VLO9VKeIWbQRKal2mF//8NY+ax5S0hT8PGSrmc1lC9r46kprK7X6xP+z2g/NotXB2jj7A8faLmbW6olzos0RyXiB9jAJ79fxD5s1Km8k/QBQ3tg8E3CxcNV/fh2ZphgPjQV9+zPVwphd2UIu9/HZsQv9w6iS1KGjrkCnb9rIv5ZKUU2fzP8aKp5P5XfkpvT0ty2oEHiECehTBVXfojwd5th59qrkVxFyl5i1wGHgXyYwe6izD9i+rOeXdOjmGyY+gIzjj+X4YokoDQr+PgAdpouRjcPMjmP/w77+5KaeM9kT4ys2+ZeG9rYQ1NiHDoBKGIEfepdXf1jYkgiJ5h9+9X/UQNPbuXKbYcZdcSyDYRJBu3DpgBg8GbshIDIF/KHOReTa3HHpVicS8zBaV5SsB0ew+4NF2CpW8UKj2tL/P1IunPd8L5AZw9F/nT4GVqdcrFLMgaX+qaNIl1oZwxl3SR8Sr169UmeFd17yzJiLp5IeMn68f92TBhtdSiQFareGC018Ik7B2rYVzITP0tkrGk+NqXsi+Gl9m+1M0FHV1v/rGfa2cJWqINaSbG/0/3dxOWTTkKVBtvAK4FYEk2dKGLMd7KQf9YvTCmW7OSxhsaxVHqINCgAAABOWAm1qVQFVAAAAB7wGfTGpBLwAIsVEY34Rrb1rjDgaDkeAAAAMAAAMABEiwwwk7KLNyjIGQjuJZPIxHkSTOB8FgQUFi+gH/2/0IALeECaqKoSi+LnfscANwWlhi+LX18+lXliFnT9U66cveddQLP8/+SuT/UnGOh2BaLyf5oO+PmfzXutNDx8v3+nBm7dskt7VFy7OLnI/P9K6UOv9OLb463Q/P1R3wwOCCVe805nY2a9Sor+dcUN1caK/JqYifgsYY2WulJaQbRXzH7HHu61WNMua3VRf1RJSoiI+F56fJL2FL14F6KLt+PGBNfjhvXxoIE9Oq49Z7ccr53/Bh2SPpGsB7W/PUOFHsWsAq8XASB0qGTVJGHPsg4mqMai3/iv5dGmnU4XW2rpAEfI/KoeAH90R1lb5/ikr5ZHxKZzQGmZ2rBNuB2fbebSkduT6fkFx4nFcIUItRjU+tla8ofaHvTR9RcAWax1ITZt2aqfu4c7TKFKf3NDMx4ziSdmEWv9x7YAQFCt0KmqcZN9eA9ZL0ur4Uz0WAb1mr8Le9lBrLaBdNTdTZG+LHgMO76+VOyK7g/WoLWAvmSa58j9QqP9pBPfdvt/zJSudOyjj5Ws8WfTK0SqyNfCdQP72zdCYcVb230KJttB1D1av1szDgfIGu6moA4iHVPCC2gQAABCdBm09JqEFomUwU8E///rUqgBGeaHRhJZYABdZhr///mDYSG80lQhx5f0Y7rFv33UymuD/ms+kA9MSnNG2FquKkGS+QF26OlIXIRWzP1Ge4akynx3L6THDB2FXlE6FxCl/u5/oe7sfvEN4M52ssUPNhLTgBthNP3qt3A/PwUhHi9dh7HdsK1DM0sVWmkdmrPRJjDPpiPccVJhoB8kyH47mr8lzuTwxXFeshEmuThsSfed9CTUixSgWkzYQs6PrJwQmGhOqdnOzvZxoukgGXlHmKNvKpj0yGsuALSpGyoshKpk+o09k+t/ifY5qWNhUKvhs+TZjfGUmz4O4yo+JkGweUA1M8JsIwibzi0GoBDgRDIBnFfgBd91KTpaV8/53qzxPbJO3Q3c0CknSiHErNmaTUjS+6WWG+G6Rr7Hd+Noxv2B4FLT/0U1iSF61XveP+AN8DawiLcT4Ro40dd//Sbhai58yTwyKqaR9pBV80D6ZUdq03Z8xRp5lzwGUg179B2f/P8ESMC4PpYJU7YwHO/cMMBPpBXZo/6krraff9htHFnxkajsHMK4uDLTdzYRnsfEfOnNbI3VSLI7HEnme2ukM8kmRa4owCVp83LMqvp/ur3BZdUoslIIiiigpGzYv6Box9LQhEAX8/xxFZTwyfdl2giG139QNklAPJF17yuK9H1poH6touGFahzGSN8ONMcao8rZyjuGOH/qY5sOF+m5nzAd20dWQl2nIiTKXuAgprmmDM2CaEjVo1hwBSKRvzsc8iDQJSmSz9sxwrWAWLFb6mPCVXz01+RpAiu+8UY8fU0JM/I8iq1VbUP2kHQGbWqBKd3v3yxU81pDtfm1hFlhfRGiY5WZpC7Kia6JpDnDTc191YY+Q5A/kwslevHSy3wlaNDboI2IxHvpHKeodJZFneXXr8F5L54YfNA/leZZ1kj9Vo/m0aPOqYFQ+rpJHfYaPMc0MTpdHeNlvYQyd9KLvxk1Iv97MuKl9cfaKRnHHn6gInWpsQ7JfHppHbMvqgXqpbE627Tz7xMXnwdIn1+QXRqy5udf9rVzJ0pLqggAATUhJoFZCbzV72h2l/CNPop5ewxL0CeAPPIWeg91DlAv55jF9cYxoPoKi3YTOGqQtv2ntGlHoJOA5qQ9nON5DVIJ0rGYHAokwGKdeWwG2FCpGc5nc7VTSn2AWhgo32RcC9HioZ5EIsv1UMRSUk4puz5ExlIXl0kevZigKLAihtPnX6JdcbSH+aKaN2HcUeh355lLzjdGoHjaBqMw8bgTPQzEk1cSIEtOjjPG3uPEWzUF3wfAcQ6rBQUF2FlGl2FzEVUk4OsCUVZWb/vQ1Ln4MR8cuLc/uW5HRxdJA3GQ9AlOplmqwqJQhLUKGt2k/CT6F2QSPfnzVDSR6TVjH6+0qdCE+kQi9tsQChAAAC1AGfbmpBLwAdwSOjCSpvQAtswX/+CQsAQigw+MuOTFYYdSYOvq5Gos0GlDKYk4KSGMslv8pztTucGVLgknZ1h+4dkTvUn7QdAun1ZRctpTysmPpESIbSKLU9jQd3T/0Hql0zLy7QO1qHVjDVzZhHRCavN6zhvsvS9lMh18XBFbo5IgusSegfI4spFzAuHQw/BZwwvavumDbhL9hCVkV6a+gMBM6uHpAqwd4oPg2WKSLfssm8JpTxflIrd5kGBYWA/Hsa89VRShY2DOVnYEzyyxPdk+yQqyhZmya32H+h9lu0o5+z/U/isja6ioSU/wHw7O01CWSH15eQHWve6T2jdRytLPPIyD0g/70FZ/Ry3HsRINn6lOPKVOSkS6YY1NrWhHYo69IZTHvA8hflB4CZOfzyYg0em47ly9D3KW13o96vM0zFucE6x2YlfAjgaN4FL2f70q6sfxyEU0RXIKPwZLUE9ur+yHviwM1MCWs3UAR3oceBYijk5WDPW65iCTjyHTZf1dg2vrRWFpzVH3sz+BLce1ZzF0EpQR/iIbxFURJZzLm0S9SkjaG5P9Qx7NDMH33ugTN6hTol92fYMb02eyHxkx459sRTf2EGmRX8VQBQjEYQcV6QjluYezsIk5QCP5Ss55ajXvs4uyQSml27OGIJypM/iDGTKiiTbKyvhPhvAb5He6Y0yTTJEpLnhF8a3klkisr9l2vUVG4e5MoTmAVMgq/3GCbhNnaV/fmJ2X+tc7KHx8gypE5F91RHgco56IvNvKF3dJNspgaU9Hx/e0Nuap7r5N/OFNvSh0jde6vVJ4pIzloCcosIB1SIS23gc65mucG0HlzpFjO9FPxKbaz2dbUYnG29q1Lp7WEAe0NtVitSAgoCQ34G1Ew994z35A6I0mLoQETp6sLaew42Pe1FERy37ajkvIDHV6YHenhQbbwLaeC5j9DyqmbWqBaMQtUAGBEAAAVTQZtzSeEKUmUwIJ///rUqgMOaHRhJZYABdZhr//LmDYRvk0iX6MdZLR76CpLSs/hAh7ETWgHlo1w2bjn6Y4ugVIk65cHVyxqVvTbXpg1AcpzkkB1BQaz/+AkkneEJ7VPYY+VYi+x74AczggWcv6jWqUsZjGhqf1Qk20iogr1SxpRD8A+BdyBH9NiR4GfJ9TiZ8wowV9VN8KaTriPIHXFNJJWeDJWzDhNRNVKtSA7fEJ5WGjHeinqHEfKYji+7P/vl2nlsAQKpThXbBXIWTmn1t6EAg2FzmnZMWravK3nypruQFR1FG9mj2sZOk+CZaeALE9uJRQxBgE2R1UhDdlvsSsJywPOed220YW1OwEtUMrgJ98N/J0coUN49Lu02hslSFX3O6Ss8WepZGozWlhh8FQ9Y/xIpv4fVZP3hgCBXcIzbxn1i1P4vmoV8cIw0k6lL0w0MC1KoF1adAiq4yYMkUgmluEAQHU12DcmBRCOgAOoX6sHmc2OJIjA8nDzZbL1FBcDVA2womDfOSNPQdiSIIowOT0e0BSxyuIdF68EpQHzSEJePOQi0y2xJDKWL7N/Yar5Fg6+DIhUpkOC7lZVcSXttkETa2OuDzwSVGCQC777yPWdJN8EI0AsmTY3xlJVxJe2rnT/+mjh9oQCkK/xpl9kmnj06l+7nVKaR2bW9c2JK04jZZfbCKvEP55Sv+aNqSKA0+zd5damMq18hh1I/dqgdEtdYrjGP1XrAEUew24Af7oK8FryllbSFOyfqCo4Dsg5+WXHDDYjCjgc9jgAwXeaV6eZpFwmhijXQxRXTZGYlRd2fdx+i+uL8fgh91vbDrP9nJDthIIe0pq31PRyo8BscKYmBydAw6+k7L6ab8x22NlQK7MZ7gfxBvRVAjctuH1A37uCXY+UsOSxE/DOhaTML6eQPSY2nnZaAbDxu44hjoCMHGfej/HQDV81HGN4euvM6MddFx94HoKE8GrzZYpKRZmlIBTySPP8cVCQliQkAp5I9TNZmyuEvgmFbmeHJAZbfUbadnlxy9BpLdHqosMZCh4Hn7Nj8Qym9DLPSJCbFcIHaau4dHRbp+hsMqnRzSPAqyXhirIFHH8n6ua54wMTi3R5WP35+UwGfgg98BzN1xpqz6ZCT6fe2bMR9eJe+UHOk+FtIwPZNk39AUxE6oefm2zR2ZYBslmpFH74TbBpG2yn8ZKvz4AD5AiNMeazL5PT3KOtwLvAQ7cYtBvzO2iExgMCgC70jUjhz91G+7z3CbifCyMxpO97OWz9QvMkydnkbKBamuql8IRnAbPOjUKP7WqvjuggKHVAEz2M7Ga0SyWccHVMjt3n5YX0aWTtu1aZdnWbr4jFxDXcXk7KPwSv4Ev0DoAF5IL3lFwnv1wpxpBOWUEyGWm0gnXWIli8RfWubx4M59vNQ2yBVneIwUn6Vy67LaSkxva+IYwza3WG0vOkYwsyEZXQnYsBiU2iiuzH9UHtCrhmRUJ8hGBhGoBLDcLDEskGussk0NSoAv9jSDfTm95AupFqQzgM83ox27Ey0YZx9JtBga1eT1kcwBNPOXMDVXfk51lTXMjtflIW6zfyFJH6Ivt3YX40TjF58zP//VHQV2yrMNgghimrr32OWdNlOG3dmVzX3JKrhPZ6IM+AGXcYAA7aFQyEWmRtdX+X6Lt0s8+3pQa1Po3g/SW24to7+S/QGnYygWmvqFUvjD3TM9yIAfODwQHxolpY6ODf6hxzwP8usQCwrYAkyTC3oufQ5JUsjZPt8wzl+DFN0I2biQOI8ugjTaxxXAkU0tRVXVfUvSfbyBgKXDtalUABsQAAAA8pBn5FFNEwT/wAVPL7sfhv9QC0mEoDsFf75w9zaW+59Cc9PSnTZMSnJKb6jz82VdRcVXMZVNi7B1fB+5AZJrnDqfE9SqeCx/PUAScx0gmNFcBmYshfgelZ2+gW0N2eJeCv94yIvUlZXpXcFrYQd/XkNL6n5siGRy3kNI3Ic0uYdiw1ea7DXjqXpZ/SN4wGUee485VWIlqQ/hDLx8N/NI9gwa0oFMxE9TMwsPe6/SKGeOSdEDkeYOqdsvPYKeo/LK43Y4+XrFYisaF1f2pALWIY6+jaZS8ZHhgQL8celWQ9rXOiVn8BzaUX9Zql+7vb7ZGN5tQkhBXMiIkjulUXUTiSJMWEWdegwRyIFaa1I7B2NBxlAD2CjKUi8DMfS/zDH2Z6pjn3Pwe1RJAG/rF2lOn/U0ewV3kCFypmrvcRW8WBBbBNCdwtmsORlIO8GBVruotM/GZt78dtigHw9jJXAGV4BkdmbU/3uHu/m1JIpbqLJryJOou8sF7zwcTwjUOzTL5q2P8mEEQi+ADWpHzpOUmKOBlDhN8TrikT9Hhza8L9TlHUGqYSWEH5fpx9HE3PWXlTcSSmFAXeLZYMG9Btnrk5LPypRIY9NhzYVxs2YNMzP5DXJtxz0A+7cIC0y8z0BFo9cSCWDogZWGdHDFc0CdLAmInZNXSVoVgtqWUiJLp8QwCwqnGigu/sI8yz3hLE+Uu3Gf3QksHjmc+h0iVB/vh9z8m3ZHQc42DzV9NgGt+ow7mqt2dS75DvDzoSKoAlaigSXkNS4Q4MXfmulR17lj7EtubdKgB40+UMCi0ziIzZp1n6tesAnz6UdZ2UWETOw09AlQnRMdTmkN+KEf5cvhHcef78wg/0XwSbnIY8GO5xwtyHy+eYW5NbKMTSiT+2cR88vFlYJwjtaES2UvNUxUePkdzYFN/uwZteRw88otNgXN/oUUARGnyyIBaCbDwQurci3bCUJJMuMeeOpNIBGAlDJoUhmdpeWP+phxuU1DGBfDhexK1GN7LyE/iLe+xoA69/yyrVyVp9e5TyHKEr+DzAJos4xnPQRLJPAD5bux7Qv0b4wat12snoZo3VQLtxMW9DEKQ9eiyUfd0Ce+8LcjIu8HZu2Aq/qYGK35Dq/bhLFGCxTYdaFC9e8Bcmajc2ZJbvgON8FrsMxqgGGaiQRoMeT6R/2VbeV859dIOe4GQtXTF0n3Qsqo4eTwJnlUrC+rGGbdtt2ez6vQEIte1lsPg+cEq3B/aiHSzm1CpAwQKD/XW732WUX7EdNX86jC24vrTZrNwqmyvqQ+AImAAACIgGfsHRBLwAeSdqwAQOtRz6Eoj6KaLrS2aBQbM/qK3YyrsacGABdIWp1ff63zAvGYHpYsW5OL9mmFbDzXlAC/WfOSE9tZuowLCgrAjCEJbPG6hwJeckYhStEy1Jli4zpIsL8V+D2V9BNKEzY2vXzg8zpErVSsRUGb/tjqQLsKjAGQD2ZkOFIzBdv66m4DCcrvp37svnuU2JbtCcHzd5E3z+FkGZRaIiLDI0/7NcRoh2KmSoTPbP/uosi9L3/KHEbp7/m9Bb7D5ruLOmM91IXGOFecaO6Qq7czCYXDxO7V2Sz6qZpEXY/irh719UPoRroBUqE354nx/J6MQ1/BHo5ilcHabWAC77K9X8GJZC04Jyznju4nnxcVQ8KrIeamKxRTWbw8lpaQhNGcJ+GwvKdZtekF9iPe2VFwXF60vqNUJvsMAbUwnlP2agG+VP/9PJGyZlC2vu0kIlWhywJQcjGycbRYfJyGubbS22WBHe/CBaoZRpmqBFG6ZSD2XGO4ujlAFx7GxNbTzJwxpMK7agMtsbuMVAbaHZ02gWV9FG2LnGpE2juxN3FY3VZolcKCWd45Nft2EiDvK5ADvU4eSskrlE6aPjzV66iGVoOOVYt0+M1NDZmf4lbYJPuvy4nyLuJ29eOgZ5aZcXeWzada9KidSCq1YpI14ZCRoMZsWWHrEDe0xZkTxOxMORKkC1yGIoi4V17n7fk2CU0gZlxloXgAAAxoQAAAiABn7JqQS8ADJOZQD6MO2Ob8RM+kgBbEGt62YBbQGnQZDoiqL29sQsVqOjqwji6Gi5tu/++ThY+iV3w1XMCRI45dk/8Iy/B1s3Vi/oFxXLZa0LgzmCwhjQ7e+kuQVoTWd/4R8NHi4Q/vrbXjioLQtFMqP8kBWes8/mRJPbS1w6ER0uB0AHV0w+qyjRESzXO5HXCwP0dgbpdFfrWMagq1OOnk8/RB7MGQv/6cZ9eF79jjnJajSaWJpKukXZ2Fas/ii9RWsnKCBhcZ+SHrKPFIAJN1xVS0qFgnX+I8SSQzM9y434qJUbwONCtwTTcJ9loHau0JDljHsGAjJCW5yE9bmo36mj4Z74L9jXB2/yF5cFdaREkOKazoybVDOFRXFhp0pXbwgUf/VfWjeDMvPXWqpixnrcDR7rfYwAplXWCczNbugE5yVjvdlzJBiIZmCESh2/Qp2SpYzi0diPY576Tuzv9uIADAjV1W56Rk0CYXqQ38M2nrMjLStQse0ABNSnyK78USOI+sblUrqVNpLQK03d/2YC/mif0Ym7KiXw4UmSux78meFmJi+1xMeO87krZr9Qu2/JZliM7yWMHwt3f+C0xGAVmj2nx3db9Sf/kLQLxqxO+dygnvJXiz/FXGE/C0OhQzLWZKZxPOu3hgubvugVdfqqS1myFtLF/k7QNwtoMc4NZnQJaCbB8tWWQTIk+qdvK3guomWbt0zZifuIAAJOAAAAE2kGbtkmoQWiZTAgl//61KoDD7GnbfQJmCaRRr/hIjY/TAAADAAADAAADAIt81Sk8hdpf3FgpnvHi+FJABZ20jpqqf+eP+dJCRAwj/3+FIOjFoINl6f1EgYR5p8DuwSG7BfcCAeKYTTWh5uZxLH7yyCy0H8QWY+Bvqk0zRLQIeKiAnpW4+SxPkat0Iu7qelLx57bcD7fWQXBHienzPifYmqE0hFeJK9U3V6kYTgFz90uBEG+7XuCiHOTNJCYSjbI5fnjkZdBYVjGZPCfAVFn3gKjF0J1Tt4n8JT5CUgTfh342nCymeVw7rcqQDvlnWD9cv/6RgNzSmMI0AaTC5zWdQqmgcz7laMpiFpobSTavOqw3XOpvrv7YfTwAN2kNqrnfvLNSMoY8wxoPouyh9ZXVXDhjE+mKvTBf2XlRvXmV+6Ujy08jRC+BvvdpOQUVm+TlzpKTxCz1XHPBPEPap9CWNJBTwCpLjZwCF63+GYqCoFYiDmrSraaoSfzatTmWEoUPhjDUyD11KHeRRbBH2jKiEypTBl/Y88G0juLNw362AYXwe03qb8qR7ywN8lYU7tG3IIrzY7uHGGb/roaOsJt2jTXECyOW9dCxCVUgmzC3994MgApxisw+Jnkl1coffG7VQmYObgR5S3LmYlqTEcxKcXHXoxLNqwSSlEreoYD2mogq+XRmBp13GjNJjP+l5IDgCidGYAG1Xi0kWjQk+DqO6ze7hrRBAcT7NyPOiao9KJ3ij1L8LoSskXYizq6/NcLURgEJjgXBS64VR4SqfIGJfC07f+xWIGXy1oRh/Pi5cCG9OS/JGjTcLakROf+hIqQhCUMxIxyOc2tu+4pdPMmgiFqeUMOJrGKRXg3NrIUIfBUiN1cGVyKehAZZJqk2cxDPL7Rnlq7jnB8QTlFIg2U9WwbVzIxn8WDEf1fv8BguNjcbJj1Ph4dAbm9x8C3QGEUKzSW/ahzPR7eBPg8xpVFB/WgQBPXVdxFU/FQ5s2Qvye82c0pHFFt9QQ4Mbt1mnx4y+IbKLSQuUx2wm0NNOcvlCe+mVywDNsSo+BNjfavWr6BjR+kAr8BZcLOC0acMf4mM5blyZDQTU9z44UK88BcfskGxFU/FQ5s2Qv+wDOi+hxZvOm9n6F4s/x7lX2fmRnw3h+H0UjORCqvxTFwfN1L6gedYNvnj9aQ4XiaG3G2GPjYOsOlNduT7/OfbGXjLELTwkOoVIJQXszPg5d/z5K4DLHJKzzUXjFjndIESoCrcS46fpNIYEaRtm/MQ+PYEqW2DLRQnxTM1/SIdh9OI0yBwaYrogrDh0XuvvdS9oiWuqMSRR7gRc5Qtx8QGmpUfEUHCjmyrjA7V0tz8sna4w8FCcha/41517VneYL8XKLCWNnY8wJQUTKhV1cp5ak+FkMCtMWmglnBX7mZRf5NPZw2C6ji8C+K+2iejZB6EKQeYJOISYWBjex01yNlDat99gHh4rfUK5YzKTiYbykgJLN+7tV8QmwdPdBbklksDcQ5aPtRkq/nfT2UAisEvOcDjOvlngJi0ojLcfqZGf97Y+N7/aiYKWkcXBEWJ741tcj4OwnlLqBZdXCELT/mPPwTc7sxKDYdXFCZHAQlt2PxcukIx4s4A9TSyeiVIZUYwe35GiN/PiQID+0iVQAAdMAAAA8FBn9RFESwT/wAVUHIDTGUSyh2UIT/55Ak2lb9AiAEfrf/D716AATg7sTTW+uRw22qBhgZ5m3HQQ0e9ILSoDUEBmRSFtGkXJ/X9f49QbPsd3VznaulaYhOvF1MrWr7jhrLPeh7sy7nDUOycjOXbHpl4ENcKttgxvWrWe/9iSleLBWMvF4JuPn1mx+Jp+fmvB/w6yM/NCf39BjrOngOj42gzWgZum/tVrqNDW5Vumhqjx6QRrZVIN86gqdQ1nXzbA1YcyctRzmR9BJ63btEbM5rHnTKJ/UVlxL1qdBkyjIP5VcSKa+7cO+P/7JF9zuo9gc4iV9RLTm6AdEmxcO7us7P/D08EltXRa2gOF5YGA8le5ep+pAedolbR1EgTQuQOXHtkpeGug67AVmq0Kn1R1On9wVnG76KkL38FiOwe1TkW506D4EDU5SihrXft8p4ngEr7AwCf5ofU5qhC6yN8IV9DFM1+G5u8EYXft7YrmIkdna5Qy6zAkNrLJAfDBn6rZKCf2W0A0DxmHnY2Rx92DHyfKDm3gmrPs29z2d4ZVUtk/hlUSEcWPQaUMnav4xfzLm7jbNtLxZGvffnRz7pg4hsLxhZ8aaGNaGyC7T+YsDBLiCr8aG3mNUpzYMZrMEar6B8zPEAZQR4bKa8DyTGse0hXcSUtapv1qZ8zj2tFLOyM6IQH2miI87Tn2/4oNm8FeIYkp7UXjw+8oAS28bDFqTeEMf9uynCkYfiWZGIf0nW8D69S0LPzY00YrX7AqV9g9o0Yqyi8hKJHwrvpatEKN70EQ+uvMHNWALqmGPQ+svpKbDvrQiufLo++jmaZgyBj8XzKFrEm3mu+FqWEoSS1UCBs7nIw9P/A0vLgFnAbsaeXdv5isg8gRLcm3v7DWfoC48PhSCcyPekYm/nlqZxxVkUExp1FTCRCbokeEmRg2dIS7x0+BtoW3X9rLVO7TTOD29VpvMmBfhxv9UCpXqIrBNnx3QG3m1mJHCCyqpA9lcUTTGPOf5Wiod6tTO/A9+2Ug54ECFTC8MRSk5n4SwbfyrFN3wURryBiB6eOoJGQh8o6LADDKgnWDxAUFxrWnzpPc620H7mnDUHF9EtKncvaWApXe99rrSGVZUv9h8rh+Kdrwh33IVg40mE45e/zsP++2L9MfRrikMmpTfurTX9tmHKXdvk1qrkPOZxA35Sude7sOoiK+HWuGGxe/sxe6Mio/8OwAOk7Sb6FnrSixk4YiFZNLtePLHEwV4Mj8dNq7SGjXWA2Y8bwC6ZOFYZYRcm9oDUhAAACmgGf9WpBLwAeZE4rzatPcjtu0qqgAAADAAAJ/5jBby4CZFPHnsgBFWBhqDqVkkefhTrdgARiu8YxAlI2EQjYj8EWhAVQqTOBSVCaouAD2jpbD9iuOgTrMEwgB5pWCQEwW4BxGrB3vPNOcYrhmU8Rkd5M0u4za24hA0sEk8NcgIxC5YHCu30xxo9vvgAiPUEVOCrGKgFtq+VfrFyp3PJHNLQcmT/KPy1bbFPAdTo/IN5dkD3shNgbuxk17IoMxcgAx7jMp9WZM72UhteFDx+R0yjvkB2Lgz2O3Yq8e2pPMN7VRonMW6pm+jmAtyNg8bRDyUW2WDlMhCk+fTtCfdXuSwKebJJwBDVjrBW1FqXaYZNEXu5FpYZJqS/aiPGdDCbmtTSLbDzh58YonjFf6D3YeU36xTXBSG0bDbDZvsWOdiIKM0z8x0JajuX40jMyq89UOl4Kw9K9D3DN1FRdg6eDy2cBBUWoPllZIVsY1XhaYXIxXUt7of8WfuY04J6gHZGJJ0kFdcrsb3dkd8oks9D4HrnmIBLoKmEDXm8pIfxlorR3DSlO8A0oDgkJRRiwobUcVOm4AXZ8ae9n8wViaHoxZFuDw8fPmPyxJmXv+WWykV21tK4/BcDH/8ZwHT1tqYyoI/ZG5xY27A5vsZfOZrfZCeqt5syOiQxyDP0fmAB3irGf7Fb/Nq9WwdjZQhkE9oOQPvt/JTM3J9Pm03gC4xJnqNN0Mkm80z3NaHvHZpkENGuo+K/QJBQKYPg/nW8EDYk3MGpHYwggU+uaPao+k4hHZuz/yTXQ7ZH/1Lxlzv6np6XyxrrlB19f9jI2I4TeF4lKqf125PgnLpiALo9BvSUeq2zJfD5kcWPHW7cSux2FcG01RoNeIaZ8tQAY8AAAAhlBm/dJqEFsmUwIJ//+tSqADk7j/QhrFgAmnEOCUkB90OqgbQstZLHbVvgAats2Udy7qhST6Nc0WBPp+YTmQF7IPg9YXfEoH+Wsvw2TYHMzmdATbHbsqnQXfPNO12VvtINVunNRvY+EEi770139fT37/Yit/VQYWQP4QAMh+0/j/mDciiM29lFxKWW/JI/ExZDTu/ge+v+rJmZIapctUU0/HCUhHx50PIPfAA525V2VJVpIpy4Wqz9FhzMDVVGW92DxUEE6aGQWoi/dwQKi/u9sSHNax51aALwCPkFGqY/5vJFpJYU0ujHGwe+eLhdIya6GSyZK12OwGHhW5Jy8HTkyT6F1ZDoIDt8/JvxXXRvt0QRhcalMNrwcrCyAmchVjbo59I+YuF1cZz+4U4/c73Uq1Ur66dTooCznuUsnU1T2Ilua54fJRCh53J/QfTJKUuVN/+6x0+kRPwO7Z6ahcSaQpRTNYSwstcXG4cOo7b15Mg+0x052CktfL6Om9Qx5BmJ8xUnnH6SpeJdAJDolMgXhIh7/cpG4aE4IhMcKLPp0vly5vH3CJHsQtGORxS43xeo8K8pwfC0MeSAJW6hX/O101AYHJsZn+p0c+Qs9FrPJxgWloLDEdgKRAs/hlDQVVXkCiuQ1bui/nfMdFO7/9h7Ub5yDEAlEdFvwIQg2Q5a4FJNUZQElS4sFhWp1sBd4eXnK0+6oYu/XlMsAAATEQZoZSeEKUmUwUVLBP/61KoARn7UMWPfBrVgRnY5PjLFay0AAAAMAAAMAABpsNrHjyRDK9yuWyQMvIjoYN6nWT7Zma2V/XjuysFm16deFXAJyjsTQT/0UFOqzRwmb6FpWevJX0yx3sRmMPZRg2HGsH38pwdQmTZOkOgw7feZ2/QNsN5E9VYeyk9wTMrTZwbAyFkqY0akobSwnEqK5/Nkor6CpuRIzdu3jh/9hOWmoknHv660N09+kmdU57nl/8qH1kEmw/uydH20gRDegmYfHp1oSpmuLgbT8XrB8rIPXIBMCn/Py2YbLxvu/P/1hcxCI3VM/i0FdR5yueCJYNF++3k+2YubjqaavHWIxcBnqy3novpu5kFrFzzlq5Y9Xv+RRUmZeMwaXSv/7yA2w35CZ4Dmy4J9fHxW89Bk0y+G1T0LjDZxY9H1hVYCtQrRnVXj6HVaBVx2qnclRsnz1E/jcI7/cDiYGBlioHcemgrWeb96ETOzpMx/e8nK33eFUm4hbUTW2HRy2zo3WDUALz1IWh2h2Y44qJcJIFsE6uOxVMd+a4iO+uDuOGcxccrZmS8cOVS46gDfgn13UagBQOAfs/1i43iSPmxL8a3t/nXf4r0StlRmgSBqTS0WJwHY6HqA+4+DqW3dPNMHSuKKAc3PlQ9eyUxXNOXLkp0zZ87P1YM9S7OoYNF2NEKwdsik1KltRg2r55T4cn2ZEf1SK5EDkhX6nO484TkfiOghhOaCsSBlbbPQru6fgXE8t+8GVfBIMa13g7WjhDSyyylX0Zadit2VHRbWPA6sbE1j+l/gxHG37R56JHGdEqY6PnGh/z3OtXxkQH+3NdAd9IoEtgjLQp0aYoRlU3ZYfERaMFNcdsCLdbsitte96wNI5ArMtRvsDbs197nk+sRfypB4D0X1PB33sXuDeTiZ9WeeMbPGmRPJtHluaEqzI7FRfh8yv3kYfHz0PVwjZkzPUUt4BFo7wGNMutyIS6vgHU1gN8FYBtNQJ6djNyaa2DF+HqKAAePFibQZd8PmGEuZmHvjBidhl+sXoAAvjxgtqSJZ4j14YH+/CTxYEEAnOJMQy8blUkuXe2ueSRbMJxnbS9rKY1u7PR7JeocyOp/T42/h+ZUj9lh6gtXbzOn7RS0SMrmsxSa/WV/V7BkMskrxj2vd/ZaxkzPKY9tJweWZ4M4sXXv2DIZPI/jQzM3YS2eyRTs3pQPkwgxOo0oHCeG0iRA9/h3oUHr/2YhLXd+oQaJJkn8DmK2SkbXgcZP0YcUsafvnmDu07N6UKr1+eJXagcJ4bSJEDnTi1e1knGBWUcuSnlbSQulYdKR2AElLgMsczVK6rI0Pn8ty5Kg6KpS/gDVJS6Rtm72rciCF+VnO5qXuvvRU2U1mXhoKntHGc2dju45ecPDyncHn4NUN5W17AURl2h+eelpQFLh55TijmT9L391JMe+H2VhJyFrvVYC2Y1TqztcXIQOG2WiIwkcZDukO3j+PQ5L9hch0K2aJqWm2CXhTMVxITvp2KuR0s2/SGDSHPup3Pkh2EtLqqE41uO635DvEkM0PnORse5ACw1vH/mQ6mB520ucGwmSk7bXWex9JIuRpzP0A9AFsCxlsUbqblMdbBrVMsAXUAAAHbAZ44akEvAAixXcHm/4KQFcG9Xr3udlcAC2tt/WJWPL4dY/ifTm5a3gNqPkam3/VQYtGEIbxmwBpmSyRskNyXwrWYoeq+tQ4G0UkYW/zCy2xGR+/t7qkitvuQmf7//P+BZVFdZFeDBt2L4+2jM9BTEkAom/x8Pr7NXlboQLXOg+MG+VYURtn+oJDNg9kyoc0g2xEH4XU4jibT7NNWt5+IDIFD+4aUwYJwTeHH4PbagFYwm8SsNjVOImLafeL8UbaJcNdQfykdhGGIo936Apc/a9MLCz0BfC3Uy1/0cMMo41uBKLajyb2lDgMkALXzCABtBmVZzzgc6o0I65hbrCYn398jcPGHp7UQthS9Gka0/yIf7l6U39MmQPQigo1F490A92uK+9viH2gBdMrQ44JhToeoXG3nPEycNj26rICo9ejojX1ouXhrAjI5LFuqSsJm9mirSe51xU5NFWZjOyKIUjjlf+vwMjQ5+wZDuKUWDCjkWjiv2Mv0fJFnMYtvdTitMn8Ns0Sn0bPOZXHWGTn+z95721qaiqkqP1tlg/R3Py2/xwPK5iy0K7oMR+oKjFkudIh1fdPpRpfIFDxClix35ovOLsmnzHYg9TnSGD+2epYZnQt8CWyqPBC7KAAAAetBmjxJ4Q6JlMCCX/61KoAGo5mwDYOoM5pXsGC6L7fsKylaVIFcXNh6mxPRPdx0xMd6midnDz0fe4zIeQLdW3iIZ8Yj36o00iCAFuuOSCYXlY+8HHt0Ztc3GNcBbj1h74IDr4xhopcBfmBYeFIwFd05mkGYcz3lKEmX5a13h7UCk5MKhBQgS9V9EHi6IzBwVqDIMaYXPMAmyqmLtB58dEh8p6i8GSvrhFvD1GbZtOzkod1PaouPxnvS8Xyw50wV/JdYlMdg3KvxujX+KSpr3Th4rf9DXb+8z8kjzfHGx/PutojdXVyHCe0+y+yLlgMJswWvn0buPUS3FuUywpXbF6JBmMosiS3IkEZwUnDXrZxJotFtV3zwtlkU0uk+mKmvBjrjE6VytiSPcZnJTtpL6BalTQ4YkdyPiLsDALZa5lIEYr9sXv48TEu0geivohYG+ZScXqSSGW+UVB5HjDdXB/+Crv3ZnWf3Tn/YaEvrErWavLmhBrbjVlcqyDYGFAjM+a6ge0yA2GgAt4xN7NJbTMUMNM+ytEvryRLnvQCbiik/MYUx7Nv65xxmriaPbLemGAZWMYGlV9EToz0b4doEclvk4ol0WZdUfryhosXyX+8RFCof3pLo8ezaP3oRX5wnq3V6AP1lsq+GFBntuQAAAU1BnlpFFTwT/wACL8sBbwDmyblxN0WztgAAAwAAAwGn6a1z//H5FUeABbrjvBLkh8SZmOcE73+3gGxyBR6SlCulI5f+vYQLyJZDIQg941WbgLznbHKgRG9Ij8tHWGIkpRXxWmWyPZhRf7Lg++LSS3EuP7gOaESS+Dvx12ZBvPjWMgSB8c7k//plLiNbR8E7kph9eLewlvLPf36qhTdcj9qR2CZQa6UqKHyTfaD55WgFDKopvWNNVkTd37RbDjbNWAdWNAU032sbpYQnlTGtsY3C67oKlhganiRNN8p/chdkwPWISKgtjVxwH4EDw9d+1qR6bHofMdhkLBWy/waCkpUGFeRBFajLT0HujMwt9bMlerpV/kMbLX/99VfoX2p1pVlMm0lU+mJrl9PtDY6WSxt8t8CLnpmEV/oQQyLZugt5f1eMULzDiM2m6XchchYAAAFDAZ57akEvAAE+lAAW9j/KVeIhDf7imExH7M/6BCLwfhW5O/+Kb4I5djvMbeBEFE80KXL/lLAhkeohLm6UTgLzJB9+BdJw8oYt12aiF0pNmti/wduooMz/FmtBzgnWLUR/JtlgzRANeYUp3mFuQPVmS1QSutIQmFkbMxHUhk8+EhOGV93sJGnw4Y1PvV+1JprUhjGXmLigKqpBFdraEIdQHynFeUmcI8WuXfJwdXlzNpWiIXymMHya49A8PeAoaUqKn6oGqXLIodXN3XC3o2gwiQ0TuQIpPxnpLS5mTPlRU3UnBPDdtiwvUmwjffvqmYSEkGVbFWUQRzE5DgcJs6tZAcY9sboa2XHLV248AnuxdugayltrTc6iT/E3zs4upxyGW3fDfqkuu8xjaZG4lCVCd8BWJk7pWqhNmaMXYot6uLOYGBEAAAPPQZp+SahBaJlMFPBL//61KoAGq+NYu30CZgmkUa/4SI2P0wAAAwAAAwAAAwBt7cH4Xvu2afl9m9gBdQgTVRVCUXxc7+cgETY3W7orSvYrAc1m/T0cbGL1tjB3/zj/QGpOMd3jVKKkf04Fc42/5t91t9IYrhFezSHHtGwMp3CVc8NtV7G6uNcB/MooepE/VBvHAWIVzuGPfNcSkk4dm2i/9z6rtu+sBX/M0Yb85aL6vpE+VuBJGkksbaUByFuWveMe01VxAfUNVMpN6RUlEZuJbxR8kxgfa71f0Vd22uZNRfhdixmatAVWwvDZRqH1MNsxFXI9rFzARLqzRMnnkdUt+y4IeKPaCjKRkxRSTBrdJo4hYk7fwqReW1ifaHZgzmQq6So6uaZf4rpJrevdngPL9ENL+XkWpmIFEQGO4gQsn4gckwCW2es2Bq6W1gXfygZH/MgYIzWIO35SLg5OHh4ZRfSGTTqDfhr0N55SCPS5mdF6ghKQnbPmS3TyiB1MACwDPgk4NJ+GzDtaCEr0xNJv4GEBCwWNb95DX0y6awSVQ7iO9J1jCKx9PAYwQB7WXAE0MwBYmwwoO3QQ7dqTmzihevrDBSpGpSLRzsTQvvNhOH29A9dv7THtw6XXZSOIBuAXwuBiwDF8RxjjWKEC2faw+w60cwrRt3S+DvVPDaGpKssaBRbU1Epv7rYaxNtoNVTffcDmL3O+edyIpF25JoVs+0JlPUBBAqVo/ZTMSXzv+xDEcSCY3TPP8lEtLgjdkl+DG+QXPkGhkeybITT0YhYSCdqJhNf8Ij9489WoezhoPLuejCaFr5KBlwo9lyJwMLeKZmRfyngHx2RVTePvoSRrBDIdLNgJshawK9HfDh6F86LkoIZZd8ff9Ql/HVU1eAsAX9Rz2BxEvaDgBSHA9TOw3KmjH52bLjL68JD8vcqPj2Hla/9lFl+uzw6L1xEYuyHrjkBtsq5wSU8KUXnbb+6rPyRAtJPXFett+PFCT/gVgYc34uAiZmhWZiJ2omD8U0G37FeLtvt/cOaHfODX+wlFMs4JMIgVBSyKX1iyT9CCqFHjT01iTv9Kfg2o9PI739XMy59CmaXBvWDvsO/c+Hq7AHsB3wKNXaBgHriO/Mtw0GmTaqQKnc29ligO59TIdfF/cNai1X7j+b8n5kMjaewsW5cEwffesduwi7vIJ3I72u3B4JVgzrWF3o/uUAi9T/abxC2hdagpxt6f7dk/5PZPTvaSdl6RgSPJ7yANCs4KvmRMinW1eTb166djaIYM5CG67V75i9zM/pEoh7uBDwfxAAAChQGenWpBLwADSut4wvoa29a4w4Gg5HgAAAMAAAMAAVbu2pzKYUX3/Dkog6dhABLW8NcaheVj7wce3Rm7hjvpP4anew98EB18Yw0R7/FA+tkK+5+5kOkb39Pfffoe6qSfctlA5sQxef3FsH10yp/dUgUX6n/qHeGaph8gfwP+AjmHnx0SHyhyKpSV9cHRGfkNs2nZyUO6nfEAyTZgogokB60nS2wRZpqasqHaxQN/CNkD/eKvaBH6kU9yNKtjeXA7QuuzoasgDT/2zDkt5zaBYFZ/SHmmuTA3mOCCz2d6NY3TWoTR9uhWMTwG2IgLuJNKCoxYSu3T5F9F1xEBhmj7p9xjOxO0ywfo5pNvgHisMnxiOFuxNG+nLcks9uTHZv1VBy5LVgrCasopGrY5gDHgCJF/eXGlxjzjKGblyubgdi8X18U545LkFu4RfW7jWC9hY88va36yobzRH0KZpFNS3053SsHS3ljOj0pDuoVQSRrxgG/XjTSqVkjTHV8/HjUo5Smtk2+VxSBmbY4gaBxkWKPsbIkHELb1Q1eB/nM/lPQn7YaEs1n+tI+gCgsJh1P3dIPxh3qZA5eJoe8zkT+oyJIH+Jb+4sqhfRz4DRt6wsDttEYrPYmIR7dM8qolB3RqJ/3p8uAWdHzOeDd7cGM44Q6239lUgVUQZpFp3sGHIu1cp2pI2VnoUUhW04oQtyB3YhmED8sIRZuN70SLxqCItzxXDosiPL8oq5cjbgOzgOhW8f51et21dUIYsNR7pUFd0LS6VsBgVrm2DbidtWYSDZZWCX20f1eT/FkDf7rKji9AR7Sv9p0Y6Tf2JStqUa9gZGToVuDC7eXbeq4+SyQ6PoCfTx/TUAAABG9tb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAA8jAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAADmnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAA8jAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACWAAAAJYAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAPIwAAEAAAAEAAAAAAxJtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAAEAAAAPgAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAK9bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAACfXN0YmwAAACxc3RzZAAAAAAAAAABAAAAoWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACWACWAEgAAABIAAAAAAAAAAEVTGF2YzYxLjE5LjEwMCBsaWJ4MjY0AAAAAAAAAAAAAAAY//8AAAA3YXZjQwFkAAz/4QAaZ2QADKzZQJhXlmhAAAADAEAAAAMBA8UKZYABAAZo6+PLIsD9+PgAAAAAFGJ0cnQAAAAAAAA3qwAAN6sAAAAYc3R0cwAAAAAAAAABAAAAHwAAIAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAANhjdHRzAAAAAAAAABkAAAACAABAAAAAAAEAAGAAAAAAAQAAIAAAAAABAACAAAAAAAIAACAAAAAAAgAAQAAAAAABAABgAAAAAAEAACAAAAAAAQAAgAAAAAACAAAgAAAAAAEAAGAAAAAAAQAAIAAAAAABAACgAAAAAAEAAEAAAAAAAQAAAAAAAAABAAAgAAAAAAEAAIAAAAAAAgAAIAAAAAABAABAAAAAAAEAAGAAAAAAAQAAIAAAAAABAACAAAAAAAIAACAAAAAAAQAAYAAAAAABAAAgAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAHwAAAAEAAACQc3RzegAAAAAAAAAAAAAAHwAACZsAAALNAAAFGwAAAp0AAAOlAAADFgAAA0MAAAWlAAAD2gAAA/oAAAPEAAAErAAAAokAAAHzAAAEKwAAAtgAAAVXAAADzgAAAiYAAAIkAAAE3gAAA8UAAAKeAAACHQAABMgAAAHfAAAB7wAAAVEAAAFHAAAD0wAAAokAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGF1ZHRhAAAAWW1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALGlsc3QAAAAkqXRvbwAAABxkYXRhAAAAAQAAAABMYXZmNjEuNy4xMDA=\" type=\"video/mp4\" />\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 15 – Load & Evaluate CNN (robust checkpoint loading + record/display video)\n",
    "cnn_model_dir = os.path.join(path_HW5, 'Models', '4_Models_CNN_merge', 'Models_Run_1')\n",
    "os.makedirs(cnn_model_dir, exist_ok=True)\n",
    "\n",
    "# If user supplied an exact path, prefer it; otherwise pick latest in folder\n",
    "user_ckpt = None\n",
    "# Example explicit path (uncomment to use): \n",
    "# user_ckpt = r\"C:\\Users\\Harsh raj\\... \\\\checkpoint_highway_cnn_ep50.pth\"\n",
    "\n",
    "ckpt = None\n",
    "if user_ckpt and os.path.exists(user_ckpt):\n",
    "    ckpt = user_ckpt\n",
    "else:\n",
    "    files = sorted(glob.glob(os.path.join(cnn_model_dir, '*.pth')))\n",
    "    if files:\n",
    "        ckpt = files[-1]\n",
    "\n",
    "print('Using CNN checkpoint:', ckpt)\n",
    "\n",
    "env_name = 'highway-fast-v0'\n",
    "# Create a fresh eval env for recording\n",
    "try:\n",
    "    eval_env = gym.make(env_name, render_mode='rgb_array')\n",
    "except Exception:\n",
    "    eval_env = gym.make(env_name)\n",
    "\n",
    "# Build agent (CNN)\n",
    "agent_cnn_eval = Agent(state_size=int(np.prod((3,84,84))), action_size=eval_env.action_space.n, network_type='cnn', seed=11)\n",
    "\n",
    "def extract_state_dict(candidate):\n",
    "    \"\"\"\n",
    "    Accept common checkpoint formats:\n",
    "    - direct state_dict (tensor mapping)\n",
    "    - dict with keys like 'qnetwork_local_state_dict', 'model_state_dict', 'state_dict'\n",
    "    - nested dicts where one value is a state-dict\n",
    "    \"\"\"\n",
    "    if not isinstance(candidate, dict):\n",
    "        return None\n",
    "    # common keys\n",
    "    for key in ('qnetwork_local_state_dict', 'qnetwork_state_dict', 'model_state_dict', 'state_dict', 'state_dicts'):\n",
    "        if key in candidate and isinstance(candidate[key], dict):\n",
    "            return candidate[key]\n",
    "    # sometimes the entire dict is a mapping of tensors already\n",
    "    # detect by checking for tensor-like values\n",
    "    if any(isinstance(v, torch.Tensor) for v in candidate.values()):\n",
    "        return candidate\n",
    "    # sometimes checkpoint stored under nested key\n",
    "    for v in candidate.values():\n",
    "        if isinstance(v, dict) and any(isinstance(x, torch.Tensor) for x in v.values()):\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "loaded_ok = False\n",
    "if ckpt:\n",
    "    raw = torch.load(ckpt, map_location=device)\n",
    "    sd = extract_state_dict(raw)\n",
    "    if sd is None:\n",
    "        print(\"Warning: couldn't find a nested state_dict; trying to use the raw checkpoint as-is.\")\n",
    "        sd = raw if isinstance(raw, dict) else None\n",
    "\n",
    "    if sd is not None:\n",
    "        # strip 'module.' prefix if saved from DataParallel\n",
    "        sd_stripped = {}\n",
    "        for k, v in sd.items():\n",
    "            newk = k\n",
    "            if k.startswith('module.'):\n",
    "                newk = k.replace('module.', '', 1)\n",
    "            sd_stripped[newk] = v\n",
    "\n",
    "        try:\n",
    "            missing, unexpected = agent_cnn_eval.qnetwork_local.load_state_dict(sd_stripped, strict=False)\n",
    "            print(\"Loaded checkpoint into CNN local network (strict=False).\")\n",
    "            print(\"Missing keys:\", missing)\n",
    "            print(\"Unexpected keys:\", unexpected)\n",
    "            loaded_ok = True\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load state_dict into CNN:\", e)\n",
    "            loaded_ok = False\n",
    "\n",
    "if not loaded_ok:\n",
    "    print(\"Proceeding with randomly initialised CNN agent (or partial loads above).\")\n",
    "\n",
    "# Evaluate and record\n",
    "video_dir = os.path.join(path_HW5, 'Videos')\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "# Use RecordVideo wrapper to ensure mp4 is created\n",
    "try:\n",
    "    rec_env = gym.wrappers.RecordVideo(eval_env, video_dir, name_prefix='cnn_eval', episode_trigger=lambda e: True)\n",
    "except Exception:\n",
    "    rec_env = eval_env  # fallback: may still render frames, moviepy steps will be taken by recorder earlier\n",
    "\n",
    "n_eval = 3\n",
    "for ep in range(n_eval):\n",
    "    res = rec_env.reset()\n",
    "    # normalise reset signature\n",
    "    if isinstance(res, tuple) and len(res) >= 1:\n",
    "        obs0 = res[0]\n",
    "    else:\n",
    "        obs0 = res\n",
    "    # obtain frames via render; make sure reset before render\n",
    "    try:\n",
    "        last = agent_cnn_eval.get_screen(rec_env.render())\n",
    "        current = agent_cnn_eval.get_screen(rec_env.render())\n",
    "    except Exception:\n",
    "        last = torch.zeros((1,3,80,80))\n",
    "        current = last.clone()\n",
    "    obs = current - last\n",
    "    done = False\n",
    "    ep_r = 0.0\n",
    "    step_count = 0\n",
    "    while not done and step_count < 2000:\n",
    "        with torch.no_grad():\n",
    "            action = agent_cnn_eval.act(obs, eps=0.0)\n",
    "        step_res = rec_env.step(action)\n",
    "        # normalise step signature\n",
    "        if len(step_res) == 5:\n",
    "            _, reward, terminated, truncated, info = step_res\n",
    "            done = bool(terminated or truncated)\n",
    "        elif len(step_res) == 4:\n",
    "            _, reward, done, info = step_res\n",
    "        else:\n",
    "            done = True\n",
    "            reward = 0.0\n",
    "        ep_r += float(reward)\n",
    "        step_count += 1\n",
    "        # update obs by rendering new frames\n",
    "        try:\n",
    "            last = current\n",
    "            current = agent_cnn_eval.get_screen(rec_env.render())\n",
    "            obs = current - last\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f'CNN eval ep {ep+1} reward {ep_r}')\n",
    "    try:\n",
    "        # close and allow recording to flush\n",
    "        rec_env.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Show latest recorded video (helper show_and_plot handles picking latest)\n",
    "try:\n",
    "    show_and_plot().show_video(video_dir, 'cnn_eval')\n",
    "except Exception as e:\n",
    "    print('Could not display video inline:', e)\n",
    "\n",
    "try:\n",
    "    eval_env.close()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437d140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge ckpt chosen for transfer: C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Models\\1_Models_merge\\Models_Run_1\\checkpoint_dqn_state_merge-v0_target_800.pth\n",
      "Loaded transfer weights (partial if mismatched).\n",
      "Fine-tune ep 10 reward 3.85\n",
      "Fine-tune ep 10 reward 3.85\n",
      "Fine-tune ep 20 reward 4.52\n",
      "Fine-tune ep 20 reward 4.52\n",
      "Fine-tune ep 30 reward 8.84\n",
      "Fine-tune ep 30 reward 8.84\n",
      "Fine-tune ep 40 reward 9.41\n",
      "Fine-tune ep 40 reward 9.41\n",
      "Fine-tune ep 50 reward 1.91\n",
      "Fine-tune ep 50 reward 1.91\n",
      "Fine-tune ep 60 reward 5.70\n",
      "Fine-tune ep 60 reward 5.70\n",
      "Fine-tune ep 70 reward 2.78\n",
      "Fine-tune ep 70 reward 2.78\n",
      "Fine-tune ep 80 reward 11.11\n",
      "Fine-tune ep 80 reward 11.11\n"
     ]
    }
   ],
   "source": [
    "# CELL 16 – Transfer Learning: Merge -> Highway-fast (fine-tune)\n",
    "# Copy weights from best merge checkpoint to highway agent and fine-tune for 80 episodes\n",
    "merge_ckpt = None\n",
    "merge_dir = os.path.join(path_HW5, 'Models', '1_Models_merge', 'Models_Run_1')\n",
    "if os.path.exists(merge_dir):\n",
    "    p = sorted(glob.glob(os.path.join(merge_dir, '*.pth')))\n",
    "    if p:\n",
    "        merge_ckpt = p[-1]\n",
    "print('Merge ckpt chosen for transfer:', merge_ckpt)\n",
    "\n",
    "env = gym.make('highway-fast-v0')\n",
    "obs_sample = _unpack_reset(env.reset())\n",
    "state_size = int(np.prod(getattr(obs_sample, 'shape', (obs_sample.size if hasattr(obs_sample,'size') else 1))))\n",
    "action_size = env.action_space.n\n",
    "agent_tl = Agent(state_size, action_size, 'linear', seed=11)\n",
    "\n",
    "if merge_ckpt:\n",
    "    ck = torch.load(merge_ckpt, map_location=device)\n",
    "    state_dict = None\n",
    "    if isinstance(ck, dict):\n",
    "        for key in ('qnetwork_local_state_dict','model_state_dict','state_dict'):\n",
    "            if key in ck:\n",
    "                state_dict = ck[key]\n",
    "                break\n",
    "        if state_dict is None and any(isinstance(v, torch.Tensor) for v in ck.values()):\n",
    "            state_dict = ck\n",
    "    else:\n",
    "        state_dict = ck\n",
    "    if state_dict is not None:\n",
    "        try:\n",
    "            agent_tl.qnetwork_local.load_state_dict(state_dict, strict=False)\n",
    "            agent_tl.qnetwork_target.load_state_dict(state_dict, strict=False)\n",
    "            print('Loaded transfer weights (partial if mismatched).')\n",
    "        except Exception as e:\n",
    "            print('Transfer load failed:', e)\n",
    "\n",
    "# Fine-tune\n",
    "fine_episodes = 80\n",
    "max_t = 600\n",
    "eps = 1.0\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.995\n",
    "model_dir_tl = os.path.join(path_HW5, 'Models', '3_Models_merge_transfer_learning_to_fastHighway', 'Models_Run_1')\n",
    "os.makedirs(model_dir_tl, exist_ok=True)\n",
    "\n",
    "for ep in range(1, fine_episodes+1):\n",
    "    obs = _unpack_reset(env.reset())\n",
    "    total = 0.0\n",
    "    for t in range(max_t):\n",
    "        action = agent_tl.act(np.asarray(obs).ravel(), eps)\n",
    "        res = env.step(action)\n",
    "        obs, reward, done, _ = _unpack_step(res)\n",
    "        total += reward\n",
    "        agent_tl.step(np.asarray(obs).ravel(), action, reward, np.asarray(obs).ravel(), done)\n",
    "        if done:\n",
    "            break\n",
    "    eps = max(eps_end, eps*eps_decay)\n",
    "    if ep % 20 == 0 or ep == fine_episodes:\n",
    "        torch.save(agent_tl.qnetwork_local.state_dict(), os.path.join(model_dir_tl, f'checkpoint_transfer_local_ep{ep}.pth'))\n",
    "    if ep % 10 == 0:\n",
    "        print(f'Fine-tune ep {ep} reward {total:.2f}')\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea544c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 17 – FIXED COLOR WRAPPER FOR HIGHWAY-V0 (5 AGENTS, REAL HIGHWAY RENDERING)\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "class ColoredMultiAgentWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Forces the first 5 vehicles in highway-v0 to be:\n",
    "        0 – RED (leader)\n",
    "        1 – BLUE\n",
    "        2 – GREEN\n",
    "        3 – YELLOW\n",
    "        4 – PURPLE\n",
    "    Colours are set on every reset and every step (highway-env overwrites them otherwise).\n",
    "    \"\"\"\n",
    "    def __init__(self, env, n_agents=5):\n",
    "        super().__init__(env)\n",
    "        self.n_agents = n_agents\n",
    "        self.colors = [\n",
    "            (1.0, 0.0, 0.0),   # red\n",
    "            (0.0, 0.0, 1.0),   # blue\n",
    "            (0.0, 1.0, 0.0),   # green\n",
    "            (1.0, 1.0, 0.0),   # yellow\n",
    "            (0.5, 0.0, 0.5)    # purple\n",
    "        ]\n",
    "\n",
    "    def _force_colors(self):\n",
    "        road = self.unwrapped.road\n",
    "        for i, veh in enumerate(road.vehicles[:self.n_agents]):\n",
    "            veh.color = self.colors[i]\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        out = self.env.reset(**kwargs)\n",
    "        if isinstance(out, tuple):\n",
    "            obs, info = out\n",
    "        else:\n",
    "            obs = out\n",
    "            info = {}\n",
    "        self._force_colors()\n",
    "        ego = self.unwrapped.observation_type.observe()\n",
    "        return [ego.copy() for _ in range(self.n_agents)], info\n",
    "\n",
    "    def step(self, actions):\n",
    "        assert len(actions) == self.n_agents\n",
    "        for veh, act in zip(self.unwrapped.road.vehicles[:self.n_agents], actions):\n",
    "            act = int(np.clip(act, 0, 4))\n",
    "            try:\n",
    "                veh.act(self.env.unwrapped.action_type.actions[act])\n",
    "            except:\n",
    "                veh.act(self.env.unwrapped.action_type.actions[1])  # IDLE\n",
    "        obs, reward, terminated, truncated, info = self.env.step(0)\n",
    "        self._force_colors()\n",
    "        ego = self.unwrapped.observation_type.observe()\n",
    "        return [ego.copy() for _ in range(self.n_agents)], reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a681508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 18 – Adaptive Trust Agent Class (updated: supports similarity + perf diff in trust updates)\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "class AdaptiveTrustAgent:\n",
    "    def __init__(self, state_size, action_size, is_leader=False, leader_agent=None, color='red', seed=0, alpha_scale=10.0):\n",
    "        self.is_leader = is_leader\n",
    "        self.leader_agent = leader_agent\n",
    "        self.color = color\n",
    "        self.alpha_scale = alpha_scale\n",
    "        self.alpha = 0.5\n",
    "        self.rewards_window = deque(maxlen=10)\n",
    "        self.leader_rewards_window = deque(maxlen=10)\n",
    "\n",
    "        # Own DQN\n",
    "        self.own_qnet_local = QNetwork_Linear(state_size, action_size, seed).to(device)\n",
    "        self.own_qnet_target = QNetwork_Linear(state_size, action_size, seed).to(device)\n",
    "        self.own_optimizer = optim.Adam(self.own_qnet_local.parameters(), lr=LR)\n",
    "        self.own_memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "\n",
    "        if not is_leader and leader_agent is not None:\n",
    "            # leader_qnet will be a reference to leader's local network (shared read-only)\n",
    "            self.leader_qnet = leader_agent.own_qnet_local\n",
    "\n",
    "    def act(self, state, eps=0.0):\n",
    "        state_t = torch.from_numpy(np.asarray(state)).float().unsqueeze(0).to(device)\n",
    "        if self.is_leader:\n",
    "            with torch.no_grad():\n",
    "                qvals = self.own_qnet_local(state_t)\n",
    "                if random.random() > eps:\n",
    "                    return int(torch.argmax(qvals).item())\n",
    "                return int(random.randrange(qvals.shape[-1]))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_own = self.own_qnet_local(state_t)\n",
    "            q_leader = self.leader_qnet(state_t)\n",
    "            q_final = self.alpha * q_leader + (1 - self.alpha) * q_own\n",
    "        if random.random() > eps:\n",
    "            return int(torch.argmax(q_final).item())\n",
    "        return int(random.randrange(q_final.shape[-1]))\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.rewards_window.append(reward)\n",
    "        self.own_memory.add(state, action, reward, next_state, done)\n",
    "        if len(self.own_memory) > BATCH_SIZE:\n",
    "            experiences = self.own_memory.sample()\n",
    "            self._learn(experiences)\n",
    "\n",
    "    def _learn(self, experiences):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        with torch.no_grad():\n",
    "            q_targets_next = self.own_qnet_target(next_states).max(1, keepdim=True)[0]\n",
    "            q_targets = rewards + GAMMA * q_targets_next * (1 - dones)\n",
    "        q_expected = self.own_qnet_local(states).gather(1, actions)\n",
    "        loss = F.mse_loss(q_expected, q_targets)\n",
    "        self.own_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.own_qnet_local.parameters(), 1.0)\n",
    "        self.own_optimizer.step()\n",
    "        # soft update own target\n",
    "        for tp, lp in zip(self.own_qnet_target.parameters(), self.own_qnet_local.parameters()):\n",
    "            tp.data.copy_(TAU * lp.data + (1.0 - TAU) * tp.data)\n",
    "\n",
    "    def update_trust(self, sim=None):\n",
    "        \"\"\"Update alpha (trust) combining similarity and recent performance difference.\"\"\"\n",
    "        # Need at least some reward history to compute perf diff\n",
    "        if len(self.rewards_window) < 1:\n",
    "            return\n",
    "        r_own = float(np.mean(self.rewards_window)) if len(self.rewards_window) > 0 else 0.0\n",
    "        r_leader = float(np.mean(self.leader_rewards_window)) if len(self.leader_rewards_window) > 0 else r_own\n",
    "        perf_diff = (r_leader - r_own)\n",
    "        # Build raw score: 0.7*sim + 0.3*(perf_diff/scale). If sim not provided, rely on perf only (sigmoid of perf_diff scaled)\n",
    "        if sim is None:\n",
    "            raw = 0.3 * (perf_diff / max(1e-6, self.alpha_scale))\n",
    "        else:\n",
    "            raw = 0.7 * float(sim) + 0.3 * (perf_diff / max(1e-6, self.alpha_scale))\n",
    "        # Sigmoid and clip\n",
    "        new_a = 1.0 / (1.0 + np.exp(-raw))\n",
    "        self.alpha = float(np.clip(new_a, 0.0, 1.0))\n",
    "\n",
    "    def copy_leader_policy(self):\n",
    "        if self.leader_agent is not None:\n",
    "            try:\n",
    "                self.leader_qnet.load_state_dict(self.leader_agent.own_qnet_local.state_dict())\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save({'own_local': self.own_qnet_local.state_dict(),\n",
    "                    'own_target': self.own_qnet_target.state_dict(),\n",
    "                    'alpha': self.alpha}, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        if isinstance(ckpt, dict) and 'own_local' in ckpt:\n",
    "            self.own_qnet_local.load_state_dict(ckpt['own_local'])\n",
    "            self.own_qnet_target.load_state_dict(ckpt['own_target'])\n",
    "            self.alpha = float(ckpt.get('alpha', self.alpha))\n",
    "        else:\n",
    "            # assume saved raw state_dict for local network\n",
    "            try:\n",
    "                self.own_qnet_local.load_state_dict(ckpt)\n",
    "            except Exception:\n",
    "                pass\n",
    "            # target may be absent\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d63b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserted cell: ColoredMultiAgentMerge wrapper — normalises observations to per-agent lists\n",
    "\n",
    "class ColoredMultiAgentMerge(gym.Wrapper):\n",
    "    \"\"\"A lightweight wrapper that exposes per-agent observations as a list and\n",
    "    provides a simple agent-color dictionary. This is intentionally conservative: it\n",
    "    does not change environment dynamics, only normalises the reset/step outputs so\n",
    "    downstream cells that expect a list of per-agent obs (leader + followers) work.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, agent_colors=None, n_agents=5):\n",
    "        super().__init__(env)\n",
    "        self.n_agents = n_agents\n",
    "        # default colours in 0..255 space; users may override by passing agent_colors dict\n",
    "        default = {\n",
    "            'red': (255,0,0), 'blue': (0,0,255), 'green': (0,255,0),\n",
    "            'yellow': (255,255,0), 'purple': (128,0,128)\n",
    "        }\n",
    "        self.agent_colors = agent_colors if agent_colors is not None else default\n",
    "\n",
    "    def _to_per_agent(self, obs):\n",
    "        # Accepts various observation formats and returns a list of length n_agents\n",
    "        try:\n",
    "            if isinstance(obs, (list, tuple)):\n",
    "                per = list(obs)\n",
    "            elif isinstance(obs, np.ndarray) and obs.ndim == 2 and obs.shape[0] == self.n_agents:\n",
    "                per = [obs[i] for i in range(self.n_agents)]\n",
    "            elif isinstance(obs, dict) and 'observation' in obs:\n",
    "                x = obs['observation']\n",
    "                if isinstance(x, np.ndarray) and x.ndim == 2 and x.shape[0] == self.n_agents:\n",
    "                    per = [x[i] for i in range(self.n_agents)]\n",
    "                else:\n",
    "                    per = [np.asarray(x) for _ in range(self.n_agents)]\n",
    "            else:\n",
    "                # fallback: replicate flattened observation across agents so code remains functional\n",
    "                arr = np.asarray(obs).ravel()\n",
    "                per = [arr.copy() for _ in range(self.n_agents)]\n",
    "        except Exception:\n",
    "            arr = np.asarray(obs).ravel()\n",
    "            per = [arr.copy() for _ in range(self.n_agents)]\n",
    "        # ensure list length\n",
    "        if len(per) < self.n_agents:\n",
    "            last = per[-1] if per else np.zeros(1,)\n",
    "            per += [last for _ in range(self.n_agents - len(per))]\n",
    "        return per\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        res = self.env.reset(**kwargs)\n",
    "        # Support both gym and gymnasium reset signatures\n",
    "        if isinstance(res, tuple) and len(res) >= 1:\n",
    "            obs = res[0]\n",
    "            info = res[1] if len(res) > 1 else {}\n",
    "        else:\n",
    "            obs = res\n",
    "            info = {}\n",
    "        per = self._to_per_agent(obs)\n",
    "        return (per, info) if isinstance(res, tuple) else per\n",
    "\n",
    "    def step(self, action):\n",
    "        res = self.env.step(action)\n",
    "        # normalise gym/gymnasium step return signatures\n",
    "        if len(res) == 5:\n",
    "            obs, rewards, terminated, truncated, info = res\n",
    "            done = bool(terminated or truncated)\n",
    "            per = self._to_per_agent(obs)\n",
    "            return per, rewards, terminated, truncated, info\n",
    "        elif len(res) == 4:\n",
    "            obs, rewards, done, info = res\n",
    "            per = self._to_per_agent(obs)\n",
    "            return per, rewards, done, info\n",
    "        else:\n",
    "            # unexpected signature: return best-effort mapping\n",
    "            try:\n",
    "                obs = res[0]\n",
    "            except Exception:\n",
    "                obs = res\n",
    "            per = self._to_per_agent(obs)\n",
    "            return per, None, True, {}\n",
    "\n",
    "# End wrapper cell — downstream evaluation expects this to exist and return per-agent obs lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c5b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 18 – HIGHWAY-V0 WRAPPER (keeps background traffic, colours only your 5 agents)\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "class ColoredMultiAgentWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    - First 5 vehicles (your agents) → RED | BLUE | GREEN | YELLOW | PURPLE\n",
    "    - All other vehicles → untouched (default grey)\n",
    "    - Shows α on each follower (pass show_alpha=[aB,aG,aY,aP])\n",
    "    - Logs crashes / safe steps\n",
    "    \"\"\"\n",
    "    def __init__(self, env, n_agents=5, show_alpha=None):\n",
    "        super().__init__(env)\n",
    "        self.n_agents   = n_agents\n",
    "        self.show_alpha = show_alpha or []\n",
    "        self.crashed    = [False] * n_agents\n",
    "\n",
    "        # RGB in [0,1] – highway-env expects this format\n",
    "        self.agent_colors = [\n",
    "            (1.0, 0.0, 0.0),   # RED   – leader\n",
    "            (0.0, 0.0, 1.0),   # BLUE\n",
    "            (0.0, 1.0, 0.0),   # GREEN\n",
    "            (1.0, 1.0, 0.0),   # YELLOW\n",
    "            (0.5, 0.0, 0.5)    # PURPLE\n",
    "        ]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _colour_my_agents(self):\n",
    "        \"\"\"Colour only the first `n_agents` vehicles.\"\"\"\n",
    "        road = self.unwrapped.road\n",
    "        for i, veh in enumerate(road.vehicles[:self.n_agents]):\n",
    "            veh.color = self.agent_colors[i]                # force colour\n",
    "            if hasattr(veh, \"crashed\") and veh.crashed:\n",
    "                self.crashed[i] = True\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def reset(self, **kwargs):\n",
    "        out = self.env.reset(**kwargs)\n",
    "        obs = out[0] if isinstance(out, tuple) else out\n",
    "        self.crashed = [False] * self.n_agents\n",
    "        self._colour_my_agents()\n",
    "        ego = self.unwrapped.observation_type.observe()\n",
    "        return [ego.copy() for _ in range(self.n_agents)], {}\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def step(self, actions):\n",
    "        assert len(actions) == self.n_agents\n",
    "        # ----- apply actions to *my* agents only -----\n",
    "        for veh, act in zip(self.unwrapped.road.vehicles[:self.n_agents], actions):\n",
    "            act = int(np.clip(act, 0, 4))\n",
    "            try:\n",
    "                veh.act(self.env.unwrapped.action_type.actions[act])\n",
    "            except Exception:\n",
    "                veh.act(self.env.unwrapped.action_type.actions[1])   # IDLE fallback\n",
    "\n",
    "        # ----- let highway-v0 step (background traffic moves) -----\n",
    "        obs, reward, terminated, truncated, info = self.env.step(0)\n",
    "\n",
    "        # ----- force colours again (highway-env may overwrite) -----\n",
    "        self._colour_my_agents()\n",
    "\n",
    "        ego = self.unwrapped.observation_type.observe()\n",
    "        return [ego.copy() for _ in range(self.n_agents)], reward, \\\n",
    "               terminated, truncated, info\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def render(self):\n",
    "        img = self.env.render()\n",
    "        if img is None:\n",
    "            return img\n",
    "\n",
    "        pil = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(pil)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "        except Exception:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # ----- label my 5 agents + α -----\n",
    "        for i, veh in enumerate(self.unwrapped.road.vehicles[:self.n_agents]):\n",
    "            if not hasattr(veh, \"position\"):\n",
    "                continue\n",
    "            x, y = veh.position\n",
    "            px = int(x * 10) % img.shape[1]      # 10 px per metre in highway-v0\n",
    "            py = int(y * 10) % img.shape[0]\n",
    "\n",
    "            if i == 0:\n",
    "                txt = \"LEADER\"\n",
    "            else:\n",
    "                a = self.show_alpha[i-1] if i-1 < len(self.show_alpha) else 0.0\n",
    "                txt = f\"F{i}: α={a:.2f}\"\n",
    "            draw.text((px, py-25), txt, fill=(255,255,255), font=font, stroke_width=1)\n",
    "\n",
    "        # ----- global status -----\n",
    "        status = \"SAFE\" if not any(self.crashed) else \"CRASHED!\"\n",
    "        draw.text((10, 10), f\"Status: {status}\", fill=(255,255,255), font=font)\n",
    "\n",
    "        return np.array(pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17e8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded leader*.pth (α=0.50)\n",
      "Resizing first layer: torch.Size([125, 5]) → (125, 25)\n",
      "Loaded follower1*.pth (α=0.50)\n",
      "Resizing first layer: torch.Size([125, 5]) → (125, 25)\n",
      "Loaded follower2*.pth (α=0.50)\n",
      "Resizing first layer: torch.Size([125, 5]) → (125, 25)\n",
      "Loaded follower3*.pth (α=0.50)\n",
      "Resizing first layer: torch.Size([125, 5]) → (125, 25)\n",
      "Loaded follower4*.pth (α=0.50)\n",
      "Resizing first layer: torch.Size([125, 5]) → (125, 25)\n",
      "Loaded trust history (200 rows)\n",
      "\n",
      "Recording: EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP1_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "Episode 1 | Safe steps: 18 | Crashed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recording: EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP2_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "Episode 2 | Safe steps: 5 | Crashed: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recording: EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n",
      "Moviepy - Building video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Videos\\demo_EP3_aB=0.67_aG=0.67_aY=0.67_aP=0.67-episode-0.mp4\n",
      "Episode 3 | Safe steps: 120 | Crashed: False\n",
      "\n",
      "Saved → C:\\Users\\Harsh raj\\web\\web-project\\changed_web\\unified_project\\Deep-Reinforcement-Learning-based-Decision-Making-in-Autonomous-Driving-TasksModels\\Data_Average_Reward\\trust_history_demo.csv\n"
     ]
    }
   ],
   "source": [
    "# CELL 19 – FULL DEMO (highway-v0) – 100 % WORKING\n",
    "import numpy as np, torch, os, glob, pandas as pd, random, gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Sigmoid\n",
    "# ----------------------------------------------------------------------\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Rename checkpoint keys\n",
    "# ----------------------------------------------------------------------\n",
    "def rename_checkpoint_keys(sd):\n",
    "    rename_map = {\n",
    "        'fc1.weight': 'net.0.weight', 'fc1.bias': 'net.0.bias',\n",
    "        'fc2.weight': 'net.2.weight', 'fc2.bias': 'net.2.bias',\n",
    "        'fc3.weight': 'net.4.weight', 'fc3.bias': 'net.4.bias',\n",
    "    }\n",
    "    return {rename_map.get(k, k): v for k, v in sd.items()}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Resize first layer (5 → 25)\n",
    "# ----------------------------------------------------------------------\n",
    "def resize_agent_first_layer(agent):\n",
    "    w = agent.own_qnet_local.net[0].weight\n",
    "    if w.shape[1] != 5:\n",
    "        return\n",
    "    print(f\"Resizing first layer: {w.shape} → (125, 25)\")\n",
    "    new_layer = torch.nn.Linear(25, 125).to(w.device)\n",
    "    with torch.no_grad():\n",
    "        new_layer.weight.zero_()\n",
    "        new_layer.weight[:, :5].copy_(w)\n",
    "        new_layer.bias.copy_(agent.own_qnet_local.net[0].bias)\n",
    "    agent.own_qnet_local.net[0] = new_layer\n",
    "    agent.own_qnet_target.net[0] = new_layer\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Load agent\n",
    "# ----------------------------------------------------------------------\n",
    "models_dir = os.path.join(path_HW5, \"Models\", \"multi_agent_adaptive\")\n",
    "def load_agent(agent, pattern):\n",
    "    files = sorted(glob.glob(os.path.join(models_dir, pattern)))\n",
    "    if not files:\n",
    "        return False\n",
    "    ckpt = torch.load(files[-1], map_location=device)\n",
    "    sd = ckpt.get('own_local') or ckpt.get('state_dict') or ckpt\n",
    "    sd = rename_checkpoint_keys(sd)\n",
    "    agent.own_qnet_local.load_state_dict(sd, strict=True)\n",
    "    agent.own_qnet_target.load_state_dict(sd, strict=True)\n",
    "    agent.alpha = float(ckpt.get('alpha', 0.5))\n",
    "    print(f\"Loaded {pattern} (α={agent.alpha:.2f})\")\n",
    "    return True\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Instantiate + load + resize\n",
    "# ----------------------------------------------------------------------\n",
    "leader = AdaptiveTrustAgent(5, 5, is_leader=True, seed=11)\n",
    "followers = [AdaptiveTrustAgent(5, 5, is_leader=False, leader_agent=leader,\n",
    "                                color=c, seed=12+i)\n",
    "             for i, c in enumerate(['blue','green','yellow','purple'])]\n",
    "\n",
    "load_agent(leader, \"leader*.pth\")\n",
    "resize_agent_first_layer(leader)\n",
    "for i, f in enumerate(followers, 1):\n",
    "    load_agent(f, f\"follower{i}*.pth\")\n",
    "    resize_agent_first_layer(f)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 6. Trust & similarity helpers\n",
    "# ----------------------------------------------------------------------\n",
    "trust_csv = os.path.join(path_HW5, \"Data_Average_Reward\", \"trust_history.csv\")\n",
    "trust_df = pd.read_csv(trust_csv) if os.path.exists(trust_csv) else None\n",
    "if trust_df is not None:\n",
    "    print(f\"Loaded trust history ({len(trust_df)} rows)\")\n",
    "\n",
    "def recent_perf(col):\n",
    "    if trust_df is None or col not in trust_df.columns:\n",
    "        return 0.0\n",
    "    return float(trust_df[col].iloc[-10:].mean())\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a = np.asarray(a).ravel()[:5]\n",
    "    b = np.asarray(b).ravel()[:5]\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    return 0.0 if na == 0 or nb == 0 else float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 7. Environment – HIGHWAY-V0 with lots of traffic\n",
    "# ----------------------------------------------------------------------\n",
    "base_cfg = {\n",
    "    \"lanes_count\": 4,\n",
    "    \"vehicles_count\": 40,          # many grey background cars\n",
    "    \"duration\": 120,\n",
    "    \"observation\": {\"type\": \"Kinematics\"},\n",
    "    \"action\": {\"type\": \"DiscreteMetaAction\"},\n",
    "}\n",
    "base = gym.make('highway-v0', render_mode='rgb_array', config=base_cfg)\n",
    "\n",
    "# <<< USE WRAPPER FROM CELL 18 >>>\n",
    "env = ColoredMultiAgentWrapper(base, n_agents=5)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 8. Demo episodes\n",
    "# ----------------------------------------------------------------------\n",
    "video_dir = os.path.join(path_HW5, \"Videos\")\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "# History dict – all columns (fixes KeyError)\n",
    "alpha_hist = {\n",
    "    \"episode\": [], \"alpha_b\": [], \"alpha_g\": [], \"alpha_y\": [], \"alpha_p\": [],\n",
    "    \"sim_b\": [], \"sim_g\": [], \"sim_y\": [], \"sim_p\": [],\n",
    "    \"crash\": [], \"safe_steps\": []\n",
    "}\n",
    "\n",
    "eps_demo = 0.07          # tiny exploration → safe driving\n",
    "\n",
    "for ep in range(1, 4):\n",
    "    obs_list, _ = env.reset()\n",
    "    leader_s = np.pad(obs_list[0][:5], (0, 20))\n",
    "    follower_s = [np.pad(obs_list[i+1][:5], (0, 20)) for i in range(4)]\n",
    "\n",
    "    r_leader = recent_perf('leader_reward')\n",
    "    r_fols   = [recent_perf(f'follower{i+1}_reward') for i in range(4)]\n",
    "\n",
    "    alphas, sims = [], []\n",
    "    for i, s in enumerate(follower_s):\n",
    "        sim = cos_sim(s, leader_s)\n",
    "        perf = r_leader - r_fols[i]\n",
    "        raw = 0.7 * sim + 0.3 * (perf / 10.0)\n",
    "        a = float(np.clip(sigmoid(raw), 0.0, 1.0))\n",
    "        followers[i].alpha = a\n",
    "        alphas.append(a)\n",
    "        sims.append(sim)\n",
    "\n",
    "    # ---- store history -------------------------------------------------\n",
    "    alpha_hist[\"episode\"].append(ep)\n",
    "    for k, v in zip(['b','g','y','p'], alphas):\n",
    "        alpha_hist[f\"alpha_{k}\"].append(v)\n",
    "    for k, v in zip(['b','g','y','p'], sims):\n",
    "        alpha_hist[f\"sim_{k}\"].append(v)\n",
    "\n",
    "    title = f\"EP{ep}_aB={alphas[0]:.2f}_aG={alphas[1]:.2f}_aY={alphas[2]:.2f}_aP={alphas[3]:.2f}\"\n",
    "    print(f\"\\nRecording: {title}\")\n",
    "\n",
    "    # ---- recorder -------------------------------------------------------\n",
    "    rec_base = gym.make('highway-v0', render_mode='rgb_array', config=base_cfg)\n",
    "    rec_env = RecordVideo(\n",
    "        ColoredMultiAgentWrapper(rec_base, 5, show_alpha=alphas),\n",
    "        video_dir,\n",
    "        name_prefix=f\"demo_{title}\",\n",
    "        episode_trigger=lambda _: True\n",
    "    )\n",
    "\n",
    "    obs_list, _ = rec_env.reset()\n",
    "    obs_list = [np.pad(o[:5], (0, 20)) for o in obs_list]\n",
    "\n",
    "    done = False\n",
    "    t = 0\n",
    "    safe_steps = 0\n",
    "    while not done and t < 1500:\n",
    "        # ---- actions with tiny exploration --------------------------------\n",
    "        act_l = leader.act(obs_list[0], eps=eps_demo)\n",
    "        acts = [int(np.clip(act_l, 0, 4))]\n",
    "        for i, f in enumerate(followers):\n",
    "            act_f = f.act(obs_list[i+1], eps=eps_demo)\n",
    "            acts.append(int(np.clip(act_f, 0, 4)))\n",
    "\n",
    "        obs_raw, _, terminated, truncated, _ = rec_env.step(acts)\n",
    "        done = terminated or truncated\n",
    "        obs_list = [np.pad(o[:5], (0, 20)) for o in obs_raw]\n",
    "\n",
    "        # ---- CRASH CHECK (fixed) -----------------------------------------\n",
    "        # highway-v0 stores crash flag on each vehicle\n",
    "        crashed_now = any(\n",
    "            getattr(veh, \"crashed\", False)\n",
    "            for veh in rec_env.unwrapped.road.vehicles[:5]\n",
    "        )\n",
    "        if not crashed_now:\n",
    "            safe_steps += 1\n",
    "        t += 1\n",
    "\n",
    "    crash = crashed_now\n",
    "    alpha_hist[\"crash\"].append(crash)\n",
    "    alpha_hist[\"safe_steps\"].append(safe_steps)\n",
    "    print(f\"Episode {ep} | Safe steps: {safe_steps} | Crashed: {crash}\")\n",
    "\n",
    "    rec_env.close()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 9. Save CSV\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.DataFrame(alpha_hist)\n",
    "csv_path = os.path.join(path_HW5, \"Data_Average_Reward\", \"trust_history_demo.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nSaved → {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970abb32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# CELL 20 – Trust evolution plot (α vs episode)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Reads generated trust history and highlights trust/distrust thresholds\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m csv1 = \u001b[43mos\u001b[49m.path.join(path_HW5, \u001b[33m'\u001b[39m\u001b[33mData_Average_Reward\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrust_history_generated.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m csv2 = os.path.join(path_HW5, \u001b[33m'\u001b[39m\u001b[33mData_Average_Reward\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrust_history.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(csv1):\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# CELL 20 – Trust evolution plot (α vs episode)\n",
    "# Reads generated trust history and highlights trust/distrust thresholds\n",
    "csv1 = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_generated.csv')\n",
    "csv2 = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history.csv')\n",
    "if os.path.exists(csv1):\n",
    "    df = pd.read_csv(csv1)\n",
    "elif os.path.exists(csv2):\n",
    "    df = pd.read_csv(csv2)\n",
    "else:\n",
    "    df = None\n",
    "\n",
    "if df is None or df.empty:\n",
    "    print('No trust history available to plot. Run CELL 19 first to generate a short trace.')\n",
    "else:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(df['episode'], df['alpha_b'], label='alpha_blue', marker='o')\n",
    "    plt.plot(df['episode'], df['alpha_g'], label='alpha_green', marker='o')\n",
    "    plt.plot(df['episode'], df['alpha_y'], label='alpha_yellow', marker='o')\n",
    "    plt.plot(df['episode'], df['alpha_p'], label='alpha_purple', marker='o')\n",
    "    # highlight trust/distrust\n",
    "    plt.axhline(0.7, color='green', linestyle='--', alpha=0.6, label='trust threshold (0.7)')\n",
    "    plt.axhline(0.3, color='red', linestyle='--', alpha=0.6, label='distrust threshold (0.3)')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Alpha (trust)')\n",
    "    plt.title('Trust evolution per follower')\n",
    "    plt.legend()\n",
    "    out_img = os.path.join(path_HW5, 'Images', 'trust_evolution_generated.png')\n",
    "    plt.savefig(out_img, dpi=300)\n",
    "    plt.show()\n",
    "    print('Saved trust evolution to', out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 21 – Similarity vs α scatter plot\n",
    "csv1 = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_generated.csv')\n",
    "if not os.path.exists(csv1):\n",
    "    print('No generated trust file found; run CELL 19 to generate data.')\n",
    "else:\n",
    "    df = pd.read_csv(csv1)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(df['sim_b'], df['alpha_b'], label='Blue', alpha=0.9, s=60)\n",
    "    plt.scatter(df['sim_g'], df['alpha_g'], label='Green', alpha=0.9, s=60)\n",
    "    plt.scatter(df['sim_y'], df['alpha_y'], label='Yellow', alpha=0.9, s=60)\n",
    "    plt.scatter(df['sim_p'], df['alpha_p'], label='Purple', alpha=0.9, s=60)\n",
    "    plt.xlabel('Cosine Similarity to Leader')\n",
    "    plt.ylabel('Alpha (trust)')\n",
    "    plt.title('Similarity vs Alpha')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.2)\n",
    "    out = os.path.join(path_HW5, 'Images', 'similarity_vs_alpha.png')\n",
    "    plt.savefig(out, dpi=300)\n",
    "    plt.show()\n",
    "    print('Saved similarity vs alpha to', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb081d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 22 – Ablation bar: Single vs Fixed α=1.0 vs Fixed α=0.0 vs Adaptive (no retraining)\n",
    "# Runs a small set of eval episodes for each condition and plots mean +/- SEM for followers (no training).\n",
    "\n",
    "def run_episode_multi(env, leader_agent, followers_list, max_steps=800):\n",
    "    \"\"\"Run a single episode and return per-agent total rewards.\"\"\"\n",
    "    r = env.reset()\n",
    "    if isinstance(r, tuple) and len(r) >= 1:\n",
    "        obs = r[0]\n",
    "    else:\n",
    "        obs = r\n",
    "    if not isinstance(obs, (list, tuple)):\n",
    "        obs = [obs for _ in range(5)]\n",
    "    totals = [0.0] * 5\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done and steps < max_steps:\n",
    "        a0 = leader_agent.act(np.asarray(obs[0]).ravel(), eps=0.0)\n",
    "        acts = [a0]\n",
    "        for i, f in enumerate(followers_list):\n",
    "            acts.append(f.act(np.asarray(obs[i+1]).ravel(), eps=0.0))\n",
    "        step_res = env.step(acts)\n",
    "        if len(step_res) == 5:\n",
    "            obs, rewards, terminated, truncated, info = step_res\n",
    "            done = bool(terminated or truncated)\n",
    "        elif len(step_res) == 4:\n",
    "            obs, rewards, done, info = step_res\n",
    "        else:\n",
    "            break\n",
    "        if isinstance(rewards, (list, tuple, np.ndarray)):\n",
    "            for i in range(min(len(rewards), 5)):\n",
    "                totals[i] += float(rewards[i])\n",
    "        else:\n",
    "            totals[0] += float(rewards)\n",
    "        steps += 1\n",
    "    return totals\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ae98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 23 – Show ablation results (image + summary table)\n",
    "from IPython.display import Image, display, HTML\n",
    "img = os.path.join(path_HW5, 'Images', 'ablation_bar_generated.png')\n",
    "if os.path.exists(img):\n",
    "    try:\n",
    "        display(Image(filename=img))\n",
    "    except Exception as e:\n",
    "        print('Could not display image inline:', e)\n",
    "else:\n",
    "    print('Ablation image not found; run CELL 22 to generate it.')\n",
    "\n",
    "csvf = os.path.join(path_HW5, 'Data_Average_Reward', 'ablation_results_generated.csv')\n",
    "if os.path.exists(csvf):\n",
    "    try:\n",
    "        df_ab = pd.read_csv(csvf)\n",
    "        display(HTML(df_ab.to_html(index=False)))\n",
    "    except Exception as e:\n",
    "        print('Could not read/display ablation CSV:', e)\n",
    "else:\n",
    "    print('Ablation CSV not found; run CELL 22 to generate it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a71434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 18 - ColoredMultiAgentWrapper for highway-v0 (color first 5 vehicles)\n",
    "try:\n",
    "    from gymnasium import Wrapper as GymWrapper\n",
    "except Exception:\n",
    "    try:\n",
    "        from gym import Wrapper as GymWrapper\n",
    "    except Exception:\n",
    "        GymWrapper = object\n",
    "\n",
    "def _norm_color(c):\n",
    "    try:\n",
    "        mx = max(c)\n",
    "    except Exception:\n",
    "        return (255, 0, 255)\n",
    "    if mx <= 1.0:\n",
    "        return tuple(int(round(x * 255)) for x in c)\n",
    "    return tuple(int(x) for x in c)\n",
    "\n",
    "class ColoredMultiAgentWrapper(GymWrapper):\n",
    "    \"\"\"Apply distinct colors to the first N vehicles (safe, idempotent).\"\"\"\n",
    "    def __init__(self, env, colors):\n",
    "        super().__init__(env)\n",
    "        self.colors = [_norm_color(c) for c in colors][:5]\n",
    "\n",
    "    def _find_vehicles(self):\n",
    "        cand_lists = []\n",
    "        try: cand = getattr(self.env.unwrapped, 'controlled_vehicles', None); \n",
    "            if cand is not None: cand_lists.append(cand)\n",
    "        except Exception: pass\n",
    "        try: road = getattr(self.env.unwrapped, 'road', None); \n",
    "            if road is not None:\n",
    "                v = getattr(road, 'vehicles', None);\n",
    "                if v: cand_lists.append(v)\n",
    "        except Exception: pass\n",
    "        try: world = getattr(self.env.unwrapped, 'world', None); \n",
    "            if world is not None:\n",
    "                v = getattr(world, 'vehicles', None); \n",
    "                if v: cand_lists.append(v)\n",
    "        except Exception: pass\n",
    "        for seq in cand_lists:\n",
    "            try:\n",
    "                if isinstance(seq, dict): seq_list = list(seq.values())\n",
    "                else: seq_list = list(seq)\n",
    "                if seq_list: return seq_list\n",
    "            except Exception: continue\n",
    "        return []\n",
    "\n",
    "    def _apply_colors(self):\n",
    "        vehicles = self._find_vehicles()\n",
    "        if not vehicles: return\n",
    "        for i, v in enumerate(vehicles[:len(self.colors)]):\n",
    "            color = self.colors[i]\n",
    "            try:\n",
    "                if hasattr(v, 'set_color'): v.set_color(color); continue\n",
    "            except Exception: pass\n",
    "            for attr in ('color', 'colour', 'color_rgb', 'fill_color', 'draw_color', '_draw_color'):\n",
    "                try: setattr(v, attr, color)\n",
    "                except Exception: pass\n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        out = super().reset(*args, **kwargs)\n",
    "        try: self._apply_colors()\n",
    "        except Exception: pass\n",
    "        return out\n",
    "\n",
    "    def step(self, action):\n",
    "        out = super().step(action)\n",
    "        try: self._apply_colors()\n",
    "        except Exception: pass\n",
    "        return out\n",
    "\n",
    "# Leader + followers color mapping for 5 agents\n",
    "AGENT_COLORS_DEMO = [(255,0,0), (0,120,255), (0,200,0), (255,255,0), (160,32,240)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 19 – Demo on highway-v0 (few episodes) with adaptive trust, checkpoint repair, action clamping\n",
    "import glob, shutil\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "def _extract_state_dict(candidate):\n",
    "    if not isinstance(candidate, dict): return None\n",
    "    for key in ('qnetwork_local_state_dict','model_state_dict','state_dict','state_dicts'):\n",
    "        if key in candidate and isinstance(candidate[key], dict): return candidate[key]\n",
    "    if any(isinstance(v, torch.Tensor) for v in candidate.values()): return candidate\n",
    "    for v in candidate.values():\n",
    "        if isinstance(v, dict) and any(isinstance(x, torch.Tensor) for x in v.values()): return v\n",
    "    return None\n",
    "\n",
    "def remap_keys_and_pad(sd, expected_in):\n",
    "    # sd: state_dict mapping; expected_in: desired input features (e.g., 25)\n",
    "    new = {}\n",
    "    # mapping heuristics: fc1 -> net.0, fc2 -> net.2, fc3 -> net.4\n",
    "    key_map = [('fc1', 'net.0'), ('fc2', 'net.2'), ('fc3', 'net.4'), ('layer1', 'net.0'), ('layer2', 'net.2')]\n",
    "    for k, v in sd.items():\n",
    "        new_k = k\n",
    "        for old, newpref in key_map:\n",
    "            if k.startswith(old):\n",
    "                new_k = k.replace(old, newpref, 1)\n",
    "                break\n",
    "        new[new_k] = v.clone() if isinstance(v, torch.Tensor) else v\n",
    "    # pad first linear 'net.0.weight' if needed\n",
    "    wname = 'net.0.weight'\n",
    "    if wname in new:\n",
    "        W = new[wname]\n",
    "        if isinstance(W, torch.Tensor) and W.ndim == 2 and W.shape[1] < expected_in:\n",
    "            out, inp = W.shape\n",
    "            W2 = torch.zeros((out, expected_in), dtype=W.dtype)\n",
    "            W2[:, :inp] = W\n",
    "            new[wname] = W2\n",
    "    return new\n",
    "\n",
    "# Build env\n",
    "env_name = 'highway-v0'\n",
    "try:\n",
    "    base = gym.make(env_name, render_mode='rgb_array')\n",
    "except Exception:\n",
    "    base = gym.make(env_name)\n",
    "cfg = {'observation': {'type':'Kinematics','vehicles_count': 40, 'features':['presence','x','y','vx','vy'],'absolute': False}, 'policy_frequency': 5}\n",
    "if hasattr(base, 'configure'): base.configure(cfg)\n",
    "else: base.unwrapped.config.update(cfg)\n",
    "env = ColoredMultiAgentWrapper(base, AGENT_COLORS_DEMO)\n",
    "\n",
    "# determine per-agent state size\n",
    "res = env.reset()\n",
    "obs0 = res[0] if isinstance(res, tuple) else res\n",
    "if isinstance(obs0, (list, tuple)) and len(obs0) > 0:\n",
    "    per_agent_size = int(np.asarray(obs0[0]).ravel().shape[0])\n",
    "else:\n",
    "    per_agent_size = 5\n",
    "action_n = env.action_space.n if hasattr(env.action_space, 'n') else 5\n",
    "print('Per-agent state size:', per_agent_size, 'Action space:', action_n)\n",
    "\n",
    "# Instantiate leader/followers\n",
    "leader = AdaptiveTrustAgent(per_agent_size, action_n, is_leader=True, seed=11)\n",
    "followers = [AdaptiveTrustAgent(per_agent_size, action_n, is_leader=False, leader_agent=leader, seed=21+i) for i in range(4)]\n",
    "\n",
    "# Load available checkpoints for leader/followers; repair state_dicts if shapes mismatch\n",
    "models_dir = os.path.join(path_HW5, 'Models', 'multi_agent_adaptive')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "def try_load_agent(agent, prefix):\n",
    "    files = sorted(glob.glob(os.path.join(models_dir, f'{prefix}*.pth')))\n",
    "    if not files: return False\n",
    "    ck = files[-1]\n",
    "    raw = torch.load(ck, map_location=device)\n",
    "    sd = _extract_state_dict(raw) or raw\n",
    "    new_sd = remap_keys_and_pad(sd, per_agent_size)\n",
    "    try:\n",
    "        missing = agent.own_qnet_local.load_state_dict(new_sd, strict=False)\n",
    "        print(f'Loaded {prefix} from', os.path.basename(ck), 'missing/unexpected:', missing)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Failed to load repaired state for', prefix, e)\n",
    "        return False\n",
    "\n",
    "_ = try_load_agent(leader, 'leader')\n",
    "for i, f in enumerate(followers): _ = try_load_agent(f, f'follower{i+1}')\n",
    "\n",
    "# Evaluation: a few episodes, record videos with alphas in filename, clamp actions\n",
    "n_eps = 3\n",
    "alpha_hist = {'episode': [], 'alpha_b': [], 'alpha_g': [], 'alpha_y': [], 'alpha_p': [], 'sim_b': [], 'sim_g': [], 'sim_y': [], 'sim_p': [], 'safe_steps': [], 'crashes': []}\n",
    "for ep in range(1, n_eps+1):\n",
    "    try: rbase = gym.make(env_name, render_mode='rgb_array')\n",
    "    except Exception: rbase = gym.make(env_name)\n",
    "    if hasattr(rbase, 'configure'): rbase.configure(cfg)\n",
    "    else: rbase.unwrapped.config.update(cfg)\n",
    "    rec_env = RecordVideo(ColoredMultiAgentWrapper(rbase, AGENT_COLORS_DEMO), os.path.join(path_HW5, 'Videos'), name_prefix=f'demo_ep{ep}', episode_trigger=lambda e: True)\n",
    "    obs_all = rec_env.reset()\n",
    "    obs_list = obs_all[0] if isinstance(obs_all, tuple) else obs_all\n",
    "    leader_state = np.asarray(obs_list[0]).ravel()\n",
    "    sims = []\n",
    "    alphas = []\n",
    "    safe_steps = 0\n",
    "    crashes = 0\n",
    "    done = False\n",
    "    t = 0\n",
    "    while not done and t < 1500:\n",
    "        a0 = int(np.clip(int(leader.act(np.asarray(obs_list[0]).ravel(), eps=0.0)), 0, 4))\n",
    "        acts = [a0]\n",
    "        for i, fol in enumerate(followers):\n",
    "            s_i = np.asarray(obs_list[i+1]).ravel() if len(obs_list) > i+1 else leader_state\n",
    "            sim = cosine_sim(s_i, leader_state)\n",
    "            sims.append(sim)\n",
    "            perf_diff = 0.0\n",
    "            raw = 0.7 * sim + 0.3 * (perf_diff / max(1e-6, getattr(fol, 'alpha_scale', 10.0)))\n",
    "            fol.alpha = float(np.clip(1.0 / (1.0 + math.exp(-raw)), 0.0, 1.0))\n",
    "            a_f = int(np.clip(int(fol.act(s_i, eps=0.0)), 0, 4))\n",
    "            acts.append(a_f)\n",
    "        step_res = rec_env.step(acts)\n",
    "        if len(step_res) == 5:\n",
    "            obs_all, rewards, terminated, truncated, info = step_res\n",
    "            done = bool(terminated or truncated)\n",
    "        else:\n",
    "            obs_all, rewards, done, info = step_res\n",
    "        try:\n",
    "            obs_list = obs_all[0] if isinstance(obs_all, tuple) else obs_all\n",
    "            speeds = []\n",
    "            for i in range(min(5, len(obs_list))):\n",
    "                s = np.asarray(obs_list[i]).ravel()\n",
    "                if s.size >= 5:\n",
    "                    vx = float(s[-2]); vy = float(s[-1]); speeds.append(np.sqrt(vx*vx + vy*vy))\n",
    "            mean_speed = float(np.mean(speeds)) if speeds else 0.0\n",
    "            if mean_speed >= 22.0: safe_steps += 1\n",
    "        except Exception: pass\n",
    "        if isinstance(info, dict) and info.get('crashed', False): crashes += 1\n",
    "        t += 1\n",
    "    try: rec_env.close()\n",
    "    except Exception: pass\n",
    "    alpha_hist['episode'].append(ep)\n",
    "    for i, fol in enumerate(followers): alpha_hist[['alpha_b','alpha_g','alpha_y','alpha_p'][i]].append(fol.alpha)\n",
    "    sims_by = [np.mean(sims[i::4]) if len(sims) >= i+1 else 0.0 for i in range(4)]\n",
    "    for i, key in enumerate(['sim_b','sim_g','sim_y','sim_p']): alpha_hist[key].append(float(sims_by[i]))\n",
    "    alpha_hist['safe_steps'].append(safe_steps)\n",
    "    alpha_hist['crashes'].append(crashes)\n",
    "\n",
    "out_csv = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_demo.csv')\n",
    "pd.DataFrame(alpha_hist).to_csv(out_csv, index=False)\n",
    "print('Saved trust demo csv to', out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 20 – Trust evolution plotting (reads trust_history_demo.csv)\n",
    "csvp = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_demo.csv')\n",
    "if os.path.exists(csvp):\n",
    "    df = pd.read_csv(csvp)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for col, lab in [('alpha_b','Blue'), ('alpha_g','Green'), ('alpha_y','Yellow'), ('alpha_p','Purple')]:\n",
    "        if col in df.columns:\n",
    "            plt.plot(df['episode'], df[col], label=lab)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Alpha')\n",
    "    plt.title('Trust Evolution (Demo)')\n",
    "    plt.legend()\n",
    "    outimg = os.path.join(path_HW5, 'Images', 'trust_evolution_demo.png')\n",
    "    os.makedirs(os.path.dirname(outimg), exist_ok=True)\n",
    "    plt.savefig(outimg)\n",
    "    plt.show()\n",
    "    print('Saved', outimg)\n",
    "else:\n",
    "    print('trust_history_demo.csv not found at', csvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 21 – Similarity vs Alpha scatter\n",
    "csvp = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_demo.csv')\n",
    "if os.path.exists(csvp):\n",
    "    df = pd.read_csv(csvp)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for sim_col, alpha_col, label in [('sim_b','alpha_b','Blue'), ('sim_g','alpha_g','Green'), ('sim_y','alpha_y','Yellow'), ('sim_p','alpha_p','Purple')]:\n",
    "        if sim_col in df.columns and alpha_col in df.columns:\n",
    "            plt.scatter(df[sim_col], df[alpha_col], label=label)\n",
    "    plt.xlabel('Cosine Similarity to Leader')\n",
    "    plt.ylabel('Alpha')\n",
    "    plt.title('Similarity vs Alpha (Demo)')\n",
    "    plt.legend()\n",
    "    outimg = os.path.join(path_HW5, 'Images', 'similarity_vs_alpha_demo.png')\n",
    "    os.makedirs(os.path.dirname(outimg), exist_ok=True)\n",
    "    plt.savefig(outimg)\n",
    "    plt.show()\n",
    "    print('Saved', outimg)\n",
    "else:\n",
    "    print('trust_history_demo.csv not found at', csvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 22 – Ablation summary (attempt to read results, else summarize demo)\n",
    "ablation_csv = os.path.join(path_HW5, 'Data_Average_Reward', 'ablation_results.csv')\n",
    "if os.path.exists(ablation_csv):\n",
    "    adf = pd.read_csv(ablation_csv)\n",
    "else:\n",
    "    # build a simple ablation from demo trust history if full ablation not available\n",
    "    demo_csv = os.path.join(path_HW5, 'Data_Average_Reward', 'trust_history_demo.csv')\n",
    "    if os.path.exists(demo_csv):\n",
    "        ddf = pd.read_csv(demo_csv)\n",
    "        # single metric: safe_steps mean as proxy (higher is better)\n",
    "        adaptive_val = ddf['safe_steps'].mean() if 'safe_steps' in ddf.columns else 0.0\n",
    "    else:\n",
    "        adaptive_val = 0.0\n",
    "    adf = pd.DataFrame({'Method': ['Single','Fixed_Alpha_1.0','Fixed_Alpha_0.0','Adaptive'], 'Score': [0.0, 0.0, 0.0, adaptive_val]})\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(adf['Method'], adf['Score'], color=['gray','tab:blue','tab:orange','tab:green'])\n",
    "plt.ylabel('Score (safe_steps proxy)')\n",
    "plt.title('Ablation: Single vs Fixed vs Adaptive')\n",
    "outimg = os.path.join(path_HW5, 'Images', 'ablation_bar_demo.png')\n",
    "os.makedirs(os.path.dirname(outimg), exist_ok=True)\n",
    "plt.savefig(outimg)\n",
    "plt.show()\n",
    "print('Saved', outimg)\n",
    "adf.to_csv(os.path.join(path_HW5, 'Data_Average_Reward', 'ablation_results_summary.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 23 – Display ablation image and CSV table\n",
    "imgp = os.path.join(path_HW5, 'Images', 'ablation_bar_demo.png')\n",
    "csvp = os.path.join(path_HW5, 'Data_Average_Reward', 'ablation_results_summary.csv')\n",
    "if os.path.exists(imgp):\n",
    "    from PIL import Image, ImageOps\n",
    "    display(Image.open(imgp))\n",
    "else:\n",
    "    print('Ablation image not found at', imgp)\n",
    "if os.path.exists(csvp):\n",
    "    print(pd.read_csv(csvp).to_markdown())\n",
    "else:\n",
    "    print('Ablation CSV not found at', csvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed3908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de21c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a3790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665e05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2baced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9860b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89099d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce92e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aeacd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17fdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd8477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4383a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412682d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
